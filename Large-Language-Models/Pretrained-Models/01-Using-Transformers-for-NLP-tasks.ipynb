{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fd2c41c-5839-4751-a833-72be70088557",
   "metadata": {},
   "source": [
    "# Use Transformer models directly\n",
    "The model page of HuggingFace provides the code for how to use the model. \n",
    "Usually, there are two ways to use HuggingFace models\n",
    "- using model & corresponding component directly\n",
    "- using pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c095af-2832-4d62-ad1a-508a19270b4c",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3f250d4-ca7e-458b-8ec4-58fd983aba74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fda6508423e04a5cb0b76269a8f01fc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eef1debbb8cd4416b01d69fb76541038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb9ad4fec31648dcbf07c1a8ed4faeaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b8117959659487897459281c354cffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "695814c1-da46-4592-9c36-22d5d2b6630b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what', 'is', 'un', '##ha', '##pp', '##iness', '?']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = \"What is unhappiness?\"\n",
    "tokens = tokenizer.tokenize(input_text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab70fa92-cdab-471f-963d-445c6f80a90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens = ['what', 'is', 'un', '##ha', '##pp', '##iness', '?']\n"
     ]
    }
   ],
   "source": [
    "print(f\"tokens = {tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54775ba7-2dd7-46b4-98d2-f23805c84de7",
   "metadata": {},
   "source": [
    "You could use `AutoTokenizer` to perform simple tokenization task. However, you could use specific Tokenizer with specific model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0742bb-6e18-4286-893d-71fe5d166baa",
   "metadata": {},
   "source": [
    "## Token Embedding\n",
    "Some Hugging Face models provide the Embedding and Position Encoding too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f7db38d-102c-48d5-9c92-c28add6e2f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79fa4111-4078-4162-a779-d1f71eff393c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b214970a484ae58917efec5d882158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc1b377f-814c-4ff3-b8b0-fa61612adf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = '''\n",
    "After a long day at work, Sarah decided to relax by taking her \n",
    "dog for a walk in the park. As they strolled along the \n",
    "tree-lined paths, Sarah's dog, Max, eagerly sniffed around, \n",
    "chasing after squirrels and birds. Sarah smiled as she watched \n",
    "Max enjoy himself, feeling grateful for the companionship and \n",
    "joy that her furry friend brought into her life.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bc7d833-1c56-4687-b6bf-006389e97289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99ba5607-d35b-40bf-b01e-2e85cc93343a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  2044,  1037,  2146,  2154,  2012,  2147,  1010,  4532,  2787,\n",
      "          2000,  9483,  2011,  2635,  2014,  3899,  2005,  1037,  3328,  1999,\n",
      "          1996,  2380,  1012,  2004,  2027, 20354,  2247,  1996,  3392,  1011,\n",
      "          7732, 10425,  1010,  4532,  1005,  1055,  3899,  1010,  4098,  1010,\n",
      "         17858, 18013,  2105,  1010, 11777,  2044, 29384,  1998,  5055,  1012,\n",
      "          4532,  3281,  2004,  2016,  3427,  4098,  5959,  2370,  1010,  3110,\n",
      "          8794,  2005,  1996, 11946,  5605,  1998,  6569,  2008,  2014, 28662,\n",
      "          2767,  2716,  2046,  2014,  2166,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer(input_text, return_tensors=\"pt\")\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d5cad8-7949-4e4d-bb44-6736cf0132e7",
   "metadata": {},
   "source": [
    "You may find that the output from `AutoTokenizer` and output from `BertTokenizer` are different. `AutoTokenizer` outputs list of strings while `BertTokenizer` outputs a dictionary with keys `input_ids`, `token_type_ids`, `attention_mask`. These fields are required for later `BertModel` input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b650ace0-b331-47fe-88a4-38a858b50a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88d0921c-442d-47ce-aca7-6424978c61b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.0052, -0.1343, -0.6812,  ...,  0.1802,  0.7480,  0.2806],\n",
      "         [-0.3172, -0.3149,  0.1389,  ..., -0.0371,  0.2483,  0.1884],\n",
      "         [-0.1847, -0.4520,  0.0046,  ...,  0.4691,  0.0633,  0.1069],\n",
      "         ...,\n",
      "         [ 0.3646, -0.0579, -0.0137,  ..., -0.1730,  0.1503,  0.5632],\n",
      "         [ 0.4776, -0.0128, -0.3064,  ...,  0.3408, -0.4373, -0.5021],\n",
      "         [-0.1040, -0.1149, -0.2204,  ...,  0.2434,  0.2328, -0.5389]]]), pooler_output=tensor([[-0.4566, -0.5551, -0.9874,  0.3900,  0.9564, -0.1897,  0.2703,  0.2485,\n",
      "         -0.9233, -0.9998, -0.8332,  0.9942,  0.9664,  0.2101,  0.8222,  0.2288,\n",
      "          0.1856, -0.1588,  0.0763,  0.9313,  0.5949,  1.0000, -0.4481,  0.2314,\n",
      "          0.3737,  0.9994, -0.8431,  0.8627,  0.8781,  0.6570,  0.3893,  0.1902,\n",
      "         -0.9928,  0.1486, -0.9738, -0.9796,  0.4188, -0.4229,  0.1664,  0.1094,\n",
      "         -0.7968,  0.2180,  1.0000, -0.3576,  0.8162, -0.0428, -1.0000,  0.1557,\n",
      "         -0.7590,  0.9882,  0.9448,  0.9985, -0.0878,  0.4744,  0.3625, -0.6109,\n",
      "         -0.3119, -0.0934, -0.0043, -0.5060, -0.4819,  0.1064, -0.9691, -0.6873,\n",
      "          0.9945,  0.8819, -0.1359, -0.2598, -0.0229, -0.2252,  0.6214,  0.2124,\n",
      "         -0.6849, -0.8436,  0.8212,  0.1508, -0.2913,  1.0000,  0.0036, -0.9661,\n",
      "          0.9807,  0.8195,  0.2852, -0.1686,  0.3659, -1.0000,  0.6071, -0.1088,\n",
      "         -0.9836,  0.1482,  0.8402, -0.2439,  0.8449,  0.1851, -0.0269, -0.7029,\n",
      "         -0.1500, -0.9880, -0.2814, -0.6606, -0.0408, -0.2495, -0.3931, -0.2755,\n",
      "          0.2621, -0.3052,  0.0066,  0.3710, -0.2591,  0.3230,  0.1100, -0.1874,\n",
      "          0.3238, -0.8649,  0.4092, -0.2141, -0.9906, -0.2955, -0.9929,  0.3923,\n",
      "         -0.4580, -0.3706,  0.7479, -0.7826,  0.3512,  0.0560, -0.9956, -1.0000,\n",
      "         -0.8318, -0.1206, -0.5016, -0.1723, -0.9600, -0.9523,  0.4266,  0.8644,\n",
      "          0.1393,  0.9999, -0.5099,  0.9094, -0.3653, -0.8077,  0.9666, -0.2376,\n",
      "          0.9022, -0.4131,  0.7105,  0.0377, -0.4703,  0.8424, -0.9471, -0.1533,\n",
      "         -0.7906, -0.8013,  0.0134,  0.9023, -0.8970, -0.9780, -0.3116,  0.0226,\n",
      "         -0.2573,  0.5168,  0.8340,  0.2850, -0.0165,  0.4289, -0.5621,  0.3022,\n",
      "         -0.3833, -0.6503,  0.1850, -0.2929, -0.9290, -0.9821, -0.4361,  0.4465,\n",
      "          0.9749,  0.6237,  0.0461,  0.9509, -0.0329,  0.8987, -0.9581,  0.9878,\n",
      "         -0.0756,  0.1901, -0.9253,  0.9141, -0.3787, -0.1561,  0.4589, -0.8994,\n",
      "         -0.6192, -0.0872, -0.2472, -0.0429, -0.9750,  0.4518, -0.2249, -0.0998,\n",
      "         -0.0584,  0.8891,  0.2005,  0.4071,  0.8534,  0.7254, -0.7686,  0.1338,\n",
      "         -0.0870, -0.0886,  0.0276,  0.9914, -0.9343,  0.0509, -0.7918, -0.9807,\n",
      "         -0.1252, -0.6118, -0.0842, -0.4558,  0.7020, -0.9864,  0.2675,  0.1829,\n",
      "          0.5036, -0.2301,  0.1249, -0.5751,  0.4710, -0.1339,  0.9835,  0.9859,\n",
      "         -0.1957, -0.9761,  0.9212, -0.9960, -0.8328, -0.5117, -0.0446,  0.0622,\n",
      "         -0.5624,  0.9211,  0.9875,  0.8989, -0.8602, -0.8753,  0.3392, -0.6167,\n",
      "         -0.1749, -0.1803,  0.9349,  0.1840,  0.5117,  0.6206, -0.6222,  0.5595,\n",
      "         -0.9971, -0.8852, -0.9992, -0.0507, -0.9818,  0.9872,  0.3842,  0.9635,\n",
      "         -0.5096, -0.7157, -0.9580, -0.4139, -0.0872,  0.2304, -0.6413, -0.2518,\n",
      "         -0.7884, -0.9520, -0.1650,  0.0494, -0.7798, -0.0194, -0.8712,  0.3139,\n",
      "          0.2343,  0.6088, -0.9756,  0.9629,  1.0000,  0.9526,  0.7692,  0.1981,\n",
      "         -1.0000, -0.9940,  0.9999, -0.9995, -1.0000, -0.7886, -0.4473, -0.1018,\n",
      "         -1.0000, -0.1061,  0.1383, -0.8349,  0.8697,  0.9358,  0.6829, -1.0000,\n",
      "          0.8175,  0.9098, -0.0985,  0.9944, -0.6677,  0.9692,  0.2409,  0.8294,\n",
      "         -0.2664,  0.3062, -0.9714, -0.1345, -0.8963, -0.9854,  1.0000, -0.0059,\n",
      "         -0.6112, -0.7145,  0.9233,  0.2263,  0.0555, -0.9500, -0.2950,  0.9767,\n",
      "          0.7963,  0.2866,  0.3408,  0.2132,  0.2354,  0.2779, -0.5943,  0.2749,\n",
      "         -0.8658,  0.3182,  0.1474,  0.6967, -0.6510, -0.9531,  0.8316, -0.5812,\n",
      "          0.9764,  1.0000,  0.9811, -0.5558,  0.7746,  0.2122,  0.3493,  1.0000,\n",
      "          0.9058, -0.9746, -0.3399,  0.8044, -0.5982, -0.6446,  0.9979, -0.1819,\n",
      "         -0.9334, -0.8635,  0.9862, -0.9813,  0.9998, -0.0856, -0.9646,  0.9309,\n",
      "          0.9156, -0.8551, -0.6129, -0.0895, -0.1076,  0.2076, -0.3835,  0.8482,\n",
      "         -0.0884,  0.1948,  0.6728,  0.9037, -0.2660,  0.0749, -0.8916, -0.7856,\n",
      "          0.9947,  0.4731,  0.0133, -0.0236, -0.1434, -0.9521, -0.9310,  0.9045,\n",
      "          1.0000, -0.4846,  0.9919,  0.2561, -0.1260,  0.0743,  0.5454,  0.4770,\n",
      "         -0.2424, -0.7969,  0.9812, -0.4633, -0.9942, -0.1814,  0.1607,  0.1351,\n",
      "          1.0000,  0.5673,  0.0601,  0.7960,  0.9996, -0.3432, -0.2052,  0.9709,\n",
      "          0.9766, -0.1621,  0.1866, -0.1103, -0.9347, -0.0258, -0.5386, -0.1122,\n",
      "         -0.8375,  0.3484, -0.9344,  0.9182,  0.9980,  0.3790,  0.0934,  0.8902,\n",
      "          1.0000, -0.9997, -0.1073,  0.9894, -0.7999, -1.0000, -0.0587, -0.3777,\n",
      "          0.0365, -0.9145, -0.0538,  0.2835, -0.9336,  0.8794,  0.9459, -0.2042,\n",
      "         -0.9708, -0.9290,  0.4375,  0.0668, -0.9995, -0.5908, -0.2626,  0.8140,\n",
      "         -0.2095, -0.8609, -0.4434, -0.3839,  0.3805, -0.0927,  0.2182,  0.9060,\n",
      "          0.9628, -0.9939, -0.8766, -0.2024, -0.2882,  0.2341, -0.0513, -0.9961,\n",
      "         -0.0046,  1.0000, -0.3414,  0.9572,  0.1888, -0.2075, -0.2007,  0.0416,\n",
      "          0.9949,  0.2879, -0.7309, -0.9557,  0.9759, -0.2951,  0.2178,  0.9649,\n",
      "          0.6835,  0.6897,  0.9920,  0.3190,  0.0456, -0.1330,  0.8979,  0.1043,\n",
      "         -0.4561, -0.2624,  0.0081, -0.3690,  0.9911,  1.0000,  0.2889,  0.9579,\n",
      "         -0.9902, -0.9821, -0.2769,  1.0000,  0.8672, -0.4080,  0.8182,  0.8663,\n",
      "         -0.0410, -0.3822,  0.1036, -0.0708,  0.1832, -0.0606,  0.9308, -0.6683,\n",
      "         -0.9791, -0.6307,  0.4542, -0.9365,  1.0000, -0.5497, -0.4108, -0.5610,\n",
      "         -0.8600, -0.9993,  0.1538, -0.9726, -0.1400,  0.0956,  0.9351,  0.0906,\n",
      "         -0.1501, -0.4507,  0.9953,  0.9040, -0.9922, -0.9454,  0.9525, -0.8733,\n",
      "          0.7971,  1.0000,  0.2562,  0.8606,  0.1969,  0.0973,  0.5152, -0.9582,\n",
      "          0.5615, -0.8542, -0.2407, -0.3378,  0.4284,  0.0968, -0.9954,  0.6033,\n",
      "          0.0756, -0.1785, -0.5333, -0.1506,  0.3212,  0.8176, -0.1210, -0.0936,\n",
      "          0.0293,  0.3290, -0.6281, -0.4741, -0.4860, -1.0000,  0.1336, -1.0000,\n",
      "          0.9507,  0.1432,  0.0317,  0.8255,  0.9823,  0.9647, -0.3584, -0.9647,\n",
      "          0.6573,  0.4681, -0.1527, -0.8515, -0.4424,  0.4663,  0.1112,  0.3611,\n",
      "         -0.8299,  0.5933, -0.3714,  1.0000, -0.0302, -0.2289, -0.2930,  0.0563,\n",
      "         -0.1794,  1.0000,  0.2903, -0.9538,  0.2328, -0.7034, -0.6143,  0.5175,\n",
      "         -0.2295, -0.8700, -0.9976,  0.6668, -0.2678, -0.5019,  0.7971, -0.2358,\n",
      "         -0.6449, -0.3373,  0.9933,  0.9846,  0.8924, -0.0151, -0.9891, -0.5655,\n",
      "          0.9349,  0.0211, -0.8164, -0.0101,  1.0000,  0.1782, -0.5593, -0.3995,\n",
      "         -0.6809,  0.0055, -0.4859,  0.4637,  0.2659,  0.8282, -0.2489,  0.8944,\n",
      "         -0.9837, -0.0497, -0.9314, -0.6009,  0.5331, -0.8751, -0.9697, -0.9772,\n",
      "          0.8425, -0.1284,  0.0734,  0.0418, -0.2494,  0.3348,  0.4290, -1.0000,\n",
      "          0.9236,  0.2304,  0.9587,  0.9542,  0.8905,  0.8714,  0.2607, -0.9674,\n",
      "         -0.4711, -0.4005,  0.0405, -0.0363,  0.4989,  0.4419,  0.3536, -0.3587,\n",
      "         -0.7931, -0.8785, -0.9984, -0.9906,  0.2304, -0.7090,  0.4777,  0.9116,\n",
      "         -0.3948,  0.2402, -0.2228, -0.9899, -0.0343,  0.5405, -0.6139, -0.1104,\n",
      "          0.3014,  0.8615,  0.2889,  0.9436, -0.9531,  0.2765, -0.9729,  0.4796,\n",
      "          0.9942, -0.9064, -0.0117,  0.7794,  0.0415,  0.1166, -0.0792,  0.2213,\n",
      "          0.9835, -0.0663,  0.4243, -0.3507, -0.0446, -0.2852,  0.0239, -0.5185,\n",
      "         -0.7353,  0.2046, -0.3640,  0.7168,  0.9855,  0.0230, -0.3046, -0.1741,\n",
      "         -0.7656, -0.8533, -0.3395,  0.2412,  0.0049,  0.8206, -0.2584,  0.9989,\n",
      "          0.2060, -0.3259, -0.3056, -0.1936,  0.6333, -0.9301, -0.4577, -0.5478,\n",
      "          0.9018,  0.3837,  1.0000, -0.8156, -0.9665, -0.8539, -0.5638,  0.1879,\n",
      "         -0.7241, -1.0000,  0.1237, -0.9831,  0.8315, -0.8337,  0.9743, -0.9634,\n",
      "         -0.6535, -0.2101,  0.9628,  0.9749, -0.3200, -0.8530,  0.1305, -0.9684,\n",
      "          0.9993,  0.6711, -0.2776,  0.2165,  0.3015, -0.9292, -0.6650,  0.3649]]), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    }
   ],
   "source": [
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6e386a-39c8-4e70-9bcb-10069c2406ca",
   "metadata": {},
   "source": [
    "There is no functional header for `BertModel` because we are using base model. We only have pooler_output & last_hidden_state. Later section, we would have other function header."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368b9fe5-c3f2-4392-946d-9fcb4542cc91",
   "metadata": {},
   "source": [
    "## Position Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e3b09aa-7e56-4eb5-9bd7-ebd001e76ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "embeddings = model.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8a29146-ebdd-4add-b371-389d12fbc562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertEmbeddings(\n",
       "  (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "  (position_embeddings): Embedding(512, 768)\n",
       "  (token_type_embeddings): Embedding(2, 768)\n",
       "  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1f5570b-77d3-48f2-92d7-979878f205d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(512, 768)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.position_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03a47717-d65e-4336-8a45-bbcc70c49ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_embeddings = embeddings.position_embeddings.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a7f3e429-bee8-4a51-99c3-bfbf928e3f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts_01 = 'The cat sat on the sofa'\n",
    "\n",
    "tokens_01 = tokenizer(input_texts_01, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9fe43c5a-4c2a-4acf-a425-5ef6ce36fd83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4, 5, 6, 7]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_ids = torch.arange(tokens_01['input_ids'].size(1), dtype=torch.long).unsqueeze(0)\n",
    "position_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1938d4e2-e50a-42e6-95e3-8e5c3a9b11d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.7505e-02, -2.5631e-02, -3.6642e-02,  ...,  3.3437e-05,\n",
       "           6.8312e-04,  1.5441e-02],\n",
       "         [ 7.7580e-03,  2.2613e-03, -1.9444e-02,  ...,  2.8910e-02,\n",
       "           2.9753e-02, -5.3247e-03],\n",
       "         [-1.1287e-02, -1.9644e-03, -1.1573e-02,  ...,  1.4908e-02,\n",
       "           1.8741e-02, -7.3140e-03],\n",
       "         ...,\n",
       "         [-3.0871e-03, -1.8956e-02, -1.8930e-02,  ...,  7.4045e-03,\n",
       "           2.0183e-02,  3.4077e-03],\n",
       "         [ 6.4257e-03, -1.7664e-02, -2.2067e-02,  ...,  6.7531e-04,\n",
       "           1.1108e-02,  3.7521e-03],\n",
       "         [ 6.2613e-04, -1.6089e-02, -7.6365e-03,  ...,  5.3390e-03,\n",
       "           1.5909e-02,  1.8119e-03]]], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_position_embeddings = position_embeddings[position_ids]\n",
    "tokens_position_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb52ec92-6b7e-4d1c-b9e2-978481f4ddf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 768])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_position_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "35a506ec-d57d-4968-a3e2-8df2e920dc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]: tensor([ 1.7505e-02, -2.5631e-02, -3.6642e-02, -2.5286e-02,  7.9709e-03,\n",
      "        -2.0358e-02, -3.7631e-03, -4.6880e-03,  6.2253e-03, -3.8342e-02,\n",
      "         1.3103e-02, -3.7083e-03, -2.1014e-02,  1.1626e-02, -3.9546e-02,\n",
      "         1.0155e-02,  1.8081e-03, -3.9818e-03,  1.6112e-02, -1.9327e-02,\n",
      "        -3.1684e-02, -2.5482e-02,  3.2621e-04,  2.0337e-02, -1.6705e-02,\n",
      "        -2.1000e-02, -7.8122e-03,  1.5647e-02, -6.3413e-03,  5.5291e-03,\n",
      "        -1.5590e-02,  4.1118e-03, -1.8160e-02,  2.1867e-03,  7.1782e-03,\n",
      "        -1.5383e-02, -3.2506e-03,  1.5954e-02,  1.8287e-02,  3.6061e-02,\n",
      "        -3.9159e-03,  4.1934e-03, -9.5806e-03, -5.0352e-03, -4.4547e-03,\n",
      "         2.0729e-03, -3.2415e-01,  3.4504e-03,  4.6929e-02, -2.1057e-02,\n",
      "         5.6190e-02,  2.3602e-02, -2.3394e-02,  2.1003e-01,  3.3293e-02,\n",
      "        -7.0262e-03, -9.4291e-03, -3.4105e-04,  2.4235e-02, -2.2936e-02,\n",
      "         1.3023e-02,  6.9495e-03, -1.2559e-01, -8.3786e-03,  6.9158e-04,\n",
      "        -9.6908e-03,  1.1022e-02, -1.6233e-02,  4.5891e-03,  1.7624e-02,\n",
      "         1.6407e-03, -2.8643e-03,  1.9049e-03, -3.2296e-03, -1.8194e-02,\n",
      "        -2.1886e-02, -1.5648e-02,  2.5684e-02, -4.9936e-03,  2.3562e-02,\n",
      "        -1.8395e-02, -9.6717e-03,  2.5410e-02, -4.8760e-05, -8.8105e-03,\n",
      "         9.5286e-03,  1.5846e-03,  1.2636e-02,  2.4764e-03, -1.2566e-03,\n",
      "         8.2184e-03,  9.0805e-03, -1.3127e-03,  1.0890e-02,  5.3625e-03,\n",
      "        -1.9172e-02,  5.6138e-02, -1.9625e-02,  1.1048e-02, -8.3684e-03,\n",
      "         3.6133e-02,  1.2793e-03,  2.4005e-02, -1.5992e-02,  8.5631e-03,\n",
      "         9.1259e-02,  2.8277e-03,  1.3483e-02,  1.5463e-03,  4.8903e-03,\n",
      "         3.1020e-02,  1.4911e-02,  4.3639e-04, -1.6668e-02,  3.0517e-02,\n",
      "        -1.0839e-02, -1.1660e-02,  1.0405e-02,  1.2686e-02, -3.3903e-03,\n",
      "        -1.9862e-02,  6.5188e-01,  9.6192e-03, -3.3159e-02,  1.5370e-02,\n",
      "        -5.5616e-03,  6.7608e-03,  1.4492e-02,  2.4171e-03, -4.1311e-03,\n",
      "         8.2794e-03,  8.4107e-03,  7.0418e-03, -1.5523e-03,  2.8606e-03,\n",
      "         1.3297e-02,  1.0176e-02,  1.5895e-02, -9.1711e-03,  7.2689e-01,\n",
      "         1.9687e-02,  5.6696e-03, -4.3766e-02,  4.5223e-02, -1.1941e-02,\n",
      "        -9.0875e-01,  8.7089e-03,  4.0234e-03,  3.6836e-03, -6.2732e-03,\n",
      "        -2.5903e-02,  2.3486e-02, -1.4213e-03, -1.4343e-02, -1.4818e-02,\n",
      "         4.5858e-03,  1.0708e-02, -6.6067e-03,  6.2841e-03, -4.2199e-01,\n",
      "         1.2323e-02, -1.1810e-02,  1.2793e-03, -7.0260e-03, -1.8832e-03,\n",
      "         2.0563e-02, -2.6487e-03,  2.2068e-02,  3.1452e-01, -1.4764e-02,\n",
      "        -3.5027e-03,  1.3407e-02,  5.3970e-03, -1.9921e-02,  1.7762e-03,\n",
      "         3.8640e-01, -1.2189e-03,  2.2024e-03,  2.5893e-03,  4.9375e-03,\n",
      "         1.4391e-03,  2.0553e-02, -7.2381e-03,  7.2454e-03, -1.8126e-02,\n",
      "        -5.1037e-03,  8.1027e-04, -2.0451e-02, -7.0203e-03,  1.0860e-02,\n",
      "         7.1849e-03,  1.8469e-02, -4.5045e-02, -1.4294e-02,  8.0818e-03,\n",
      "         5.7837e-03, -9.4472e-04,  6.8269e-03, -2.0317e-02, -2.6126e-03,\n",
      "        -3.4113e-02,  5.6174e-03,  6.0332e-02, -2.1331e-02,  1.9540e-02,\n",
      "         1.6436e-02, -9.8098e-04, -5.8153e-03, -2.0590e-03,  1.0550e-02,\n",
      "         6.8645e-03, -9.9844e-03,  2.3770e-02, -7.9433e-03, -1.3178e-02,\n",
      "        -2.2934e-01,  8.4790e-02,  2.5572e-02,  3.5307e-02,  5.2829e-03,\n",
      "         1.4837e-02,  2.1980e-02, -1.6677e-02,  1.3071e-02,  8.3027e-03,\n",
      "         2.0513e-01,  2.7536e-02,  2.3536e-03, -2.7986e-03, -3.3447e-02,\n",
      "         1.2734e-02,  1.7052e-02,  1.9349e-03,  1.5361e-02,  1.2531e-03,\n",
      "         1.5568e-02,  5.7357e-03,  1.4621e-02, -4.5688e-03,  1.0091e-02,\n",
      "         3.2851e-03, -2.5840e-02,  1.0089e-02,  8.6992e-03, -1.1779e-02,\n",
      "         1.6043e-02,  2.0411e-02, -1.6397e-02, -2.1296e-03,  9.7188e-03,\n",
      "        -2.6659e-03, -4.4403e-02,  1.0044e-02,  1.2824e-02,  2.3059e-02,\n",
      "        -9.6372e-04,  1.6740e-02, -4.4114e-03,  5.0547e-03,  4.4268e-04,\n",
      "        -9.4886e-03, -1.1327e-02,  1.5871e-02,  3.9782e-02,  5.0631e-03,\n",
      "        -1.1639e-02,  2.3399e-03, -2.3734e-03,  1.6139e-03,  1.2528e-02,\n",
      "         7.9118e-04,  2.4104e-02,  1.2450e-02,  1.8565e-02, -3.0351e-02,\n",
      "        -2.2327e-02,  1.7613e-03,  1.2733e-02,  2.0701e-02, -1.5531e-02,\n",
      "        -5.1246e-03, -1.1266e-02,  2.5240e-02, -1.2041e-02,  8.0863e-03,\n",
      "         1.0252e-02,  1.0456e-02, -9.6895e-03, -3.8834e-03,  1.1450e-02,\n",
      "        -9.2728e-04, -5.9756e-02,  9.4205e-03,  6.5094e-03,  2.1229e-02,\n",
      "         2.5527e-02,  1.1935e-01, -2.0504e-02, -1.9689e-02, -3.3945e-02,\n",
      "        -3.5460e-02, -3.4517e-03,  3.2727e-02,  7.1467e-04, -1.1326e-01,\n",
      "         3.6528e-03, -2.8121e-02, -4.4089e-03, -9.4873e-01, -8.2579e-03,\n",
      "         9.5700e-03,  6.4909e-03,  2.1591e-02,  8.1766e-03,  1.8731e-02,\n",
      "        -1.6474e-02, -1.0829e-03,  1.0172e-03,  3.2228e-02,  6.8539e-02,\n",
      "         1.7401e-02,  7.8202e-03,  2.4881e-02, -1.6393e-02,  5.6342e-03,\n",
      "         8.5616e-03,  6.8291e-03,  8.6377e-03,  1.7692e-02,  1.7297e-02,\n",
      "        -6.7138e-03, -1.0759e-02,  3.5961e-03,  2.2160e-02, -4.2854e-02,\n",
      "        -1.1691e-02,  1.8538e-02, -7.4865e-03, -4.0911e-03,  4.9445e-03,\n",
      "        -2.2151e-02,  1.2028e-02, -1.2410e-02,  9.0356e-03,  1.1494e-03,\n",
      "         6.0516e-04,  2.3537e-02,  8.4044e-03,  1.5781e-03,  9.6821e-03,\n",
      "        -2.7867e-03, -6.9697e-04,  2.6148e-02,  3.1301e-02, -2.6888e-04,\n",
      "        -1.0100e-02, -2.2481e-02,  1.7974e-02,  9.4639e-03, -1.8956e-03,\n",
      "         2.5275e-02, -2.9577e-03,  2.2835e-02, -3.1423e-02,  1.4726e-02,\n",
      "         2.0035e-02,  5.7235e-03,  5.9595e-03, -1.5237e-02, -1.1721e-02,\n",
      "         1.8794e-02, -3.1860e-02,  9.3756e-03, -3.3659e-03, -7.0440e-03,\n",
      "        -1.6939e-02, -2.4611e-02, -5.7935e-03, -2.5973e-02,  2.0024e-02,\n",
      "         1.2339e-02, -3.2978e-01, -7.7871e-03,  5.2889e-03, -1.7882e-04,\n",
      "         5.6175e-03,  1.5720e-03,  2.5779e-02,  3.3703e-04,  1.3233e-02,\n",
      "         2.5225e-04, -1.4475e-02,  1.3179e-04, -1.1676e-02, -4.0976e-02,\n",
      "        -1.4450e-02, -1.1084e-02,  6.3686e-03, -5.1365e-03, -5.6728e-03,\n",
      "         1.1272e-02, -2.7303e-02,  7.4305e-04, -1.9126e-02,  4.0409e-03,\n",
      "        -7.6709e-03,  1.7460e-04,  1.0794e-02, -4.1752e-04, -4.4411e-03,\n",
      "         7.3960e-03,  4.5082e-03, -4.0728e-03, -1.8424e-02,  1.4320e-02,\n",
      "         2.0292e-02, -2.4252e-02, -5.3503e-03,  1.9122e-03,  1.2734e-01,\n",
      "        -4.7360e-04, -1.0241e-02,  1.9003e-02, -1.5879e-02, -4.0979e-03,\n",
      "         3.7665e-03,  1.3119e-02,  1.5590e-03,  3.9763e-03, -1.1468e-02,\n",
      "        -8.9788e-03, -6.0455e-03,  1.6735e-02,  3.0492e-02, -1.3776e-02,\n",
      "        -5.8501e-04,  1.5180e-02,  1.0955e-03,  3.2886e-02,  2.3517e-02,\n",
      "         1.0032e-02,  2.7367e-02, -1.6620e-02,  2.1917e-01, -1.0341e-03,\n",
      "        -7.4027e-03,  1.4238e-02,  2.4172e-02,  1.6287e-02,  7.0452e-03,\n",
      "         8.3882e-03,  3.3072e-02,  2.4348e-03, -8.7163e-03, -3.6727e-03,\n",
      "         3.5672e-03,  1.2795e-02, -5.3726e-03, -2.3503e-02,  1.7497e-04,\n",
      "         6.9914e-03,  3.4912e-03,  1.3422e-02,  1.2181e-02, -1.6444e-02,\n",
      "         3.4791e-02,  4.5028e-03, -2.6507e-03,  1.1464e-02,  2.6311e-03,\n",
      "        -1.2270e-01,  6.4825e-03, -2.7863e-03,  6.9993e-03, -2.3653e-03,\n",
      "         9.4770e-03,  3.1413e-02,  1.0011e-02,  9.1822e-03,  1.3455e-02,\n",
      "        -1.0323e-03,  2.0490e-02, -9.8146e-02,  1.3409e-02, -2.3443e-03,\n",
      "         1.7107e-02,  7.8784e-03,  7.5301e-03,  1.5177e-02, -5.9594e-03,\n",
      "         8.5675e-03,  2.6277e-02,  2.2813e-02,  1.4519e-04,  3.2599e-04,\n",
      "         1.7282e-04,  6.2644e-02,  1.9797e-02, -6.3587e-03, -3.4485e-02,\n",
      "         2.1221e-02, -6.4414e-03, -4.0100e-03, -1.9835e-02, -4.3419e-03,\n",
      "         3.3695e-03, -7.4205e-03, -5.6398e-03,  4.5072e-03, -3.2565e-02,\n",
      "         1.0115e-02, -7.4983e-03, -1.2862e-02, -6.3516e-03,  4.0671e-03,\n",
      "        -9.3837e-03, -2.1018e-03,  1.5547e-01, -4.2472e-03,  5.7451e-03,\n",
      "        -1.9098e-02,  9.8005e-03,  3.5179e-02, -1.8818e-03, -4.9677e-03,\n",
      "        -3.2048e-03, -9.1385e-04,  8.6986e-03, -7.0507e-05,  1.5667e-01,\n",
      "         1.9063e-02, -2.4499e-02, -1.1735e-02, -2.9379e-03, -1.1983e-02,\n",
      "        -1.9183e-02,  1.9416e-02,  8.8835e-03, -1.6147e-02,  1.8196e-04,\n",
      "         5.3792e-03,  2.5585e-01,  1.1422e-02,  2.0804e-02,  2.4546e-02,\n",
      "         2.9866e-01,  1.0152e-02,  3.9511e-03, -2.7023e-02, -1.0196e-03,\n",
      "         1.6320e-02, -2.0540e-02,  3.3763e-03,  1.6744e-02,  2.0203e-03,\n",
      "        -4.8061e-03, -9.7751e-03, -1.7677e-02,  1.9532e-02,  1.5034e-02,\n",
      "        -6.6859e-03,  2.2049e-02,  4.6367e-04,  1.7977e-03,  1.2669e-02,\n",
      "         8.7805e-03,  1.4979e-02,  6.9492e-04, -8.9355e-03,  1.3941e-04,\n",
      "        -2.3063e-02,  3.7799e-04,  8.7719e-03, -2.4581e-03,  1.0717e-02,\n",
      "         2.6679e-02,  1.0049e-02, -8.0140e-02,  5.4949e-03, -1.1633e-02,\n",
      "        -5.6149e-03,  1.6792e-02, -1.1923e-02,  1.9082e-02,  4.2496e-03,\n",
      "         4.7834e-03,  3.5625e-03,  5.8569e-03, -8.8028e-03, -6.8365e-03,\n",
      "        -3.0928e-03, -5.0439e-03,  6.4757e-03, -8.1023e-03,  1.4648e-02,\n",
      "         8.0872e-03,  1.4831e-02, -2.8859e-03, -4.4945e-03,  6.9385e-03,\n",
      "        -1.8887e-02, -2.2511e-02,  2.9238e-03,  1.2216e-02,  4.2561e-03,\n",
      "         7.2955e-03,  1.9166e-03,  2.2116e-03, -4.4950e-02,  2.0063e-02,\n",
      "        -1.3939e-02, -3.4170e-02, -3.1267e-03, -2.0533e-02, -1.0256e-01,\n",
      "        -1.8266e-03, -2.3904e-04,  1.0051e-03,  1.8212e-03,  4.0255e-03,\n",
      "         2.6141e-03,  1.9518e-02,  1.2558e-02,  1.3015e-02, -7.4366e-03,\n",
      "        -6.5410e-03,  3.8342e-03,  6.6623e-03,  5.0341e-03,  8.7520e-04,\n",
      "        -1.3081e-02, -8.2202e-03, -6.8843e-03,  1.2364e-02,  4.5694e-02,\n",
      "         4.1613e-03,  2.0308e-02,  2.5631e-02,  9.1870e-03, -6.5009e-03,\n",
      "         2.2024e-02, -2.0790e-02, -1.8700e-02, -9.1874e-03,  1.3257e-03,\n",
      "         1.4050e-02,  5.0912e-03,  2.9035e-03,  1.8289e-02, -4.1350e-04,\n",
      "         1.5029e-02,  1.0934e-02, -4.5056e-03, -9.9480e-04, -1.2336e-01,\n",
      "         2.0185e-02, -2.4074e-03, -2.4618e-02,  5.7208e-03, -7.3090e-03,\n",
      "         4.0453e-02, -2.2656e-03,  5.6932e-03, -1.9009e-02,  1.1463e-02,\n",
      "         1.9616e-03, -1.3426e-02, -1.1078e-02,  1.8988e-03,  6.7412e-03,\n",
      "         9.3443e-02, -8.5396e-03, -5.6580e-04,  1.6913e-03, -9.2930e-03,\n",
      "        -6.3114e-03,  1.8382e-02,  3.1378e-03,  9.6800e-03,  2.1284e-02,\n",
      "         6.7384e-03,  6.3250e-03, -2.2476e-02,  6.8591e-03, -2.8697e-02,\n",
      "         8.3506e-03,  5.9408e-03, -9.9174e-03,  1.2224e-03,  6.6172e-04,\n",
      "        -1.6487e-02,  2.0375e-03, -3.0691e-03,  2.2103e-02, -1.8485e-02,\n",
      "         2.5168e-02, -3.9419e-03, -9.7256e-03,  5.7918e-03, -1.6386e-01,\n",
      "        -6.6933e-04,  2.1050e-02,  6.4642e-03,  7.1504e-03, -4.5565e-03,\n",
      "        -6.7070e-03,  2.7318e-02,  5.1716e-03,  7.9944e-03,  1.1062e-02,\n",
      "         1.5329e-02, -1.1144e-02,  1.8286e-03,  9.6480e-03, -3.3606e-02,\n",
      "         1.5001e-02, -7.6591e-03,  4.6364e-03,  6.7793e-03, -1.3053e-02,\n",
      "         7.3410e-03,  5.1561e-03, -6.3039e-03, -3.5430e-03, -3.2766e-03,\n",
      "         6.2938e-03,  1.4051e-03,  6.9016e-03, -6.4731e-03,  1.0552e-02,\n",
      "        -9.1094e-03,  2.9611e-02, -1.8712e-03, -7.7511e-02,  1.1208e-03,\n",
      "         2.1730e-03,  1.7572e-02,  1.3308e-02, -1.1261e-02,  8.3347e-03,\n",
      "        -3.8060e-02,  1.7906e-03, -5.9467e-03, -1.5071e-02, -2.9334e-03,\n",
      "         2.1605e-02,  1.9946e-03, -8.8466e-03,  7.7241e-03,  5.5256e-03,\n",
      "        -6.2419e-03,  4.4767e-03, -1.0550e-02, -1.7457e-02,  5.3368e-03,\n",
      "         1.8447e-02, -1.2709e-02, -1.4460e-03,  4.9704e-03,  7.1674e-03,\n",
      "         4.0483e-03, -3.4331e-02,  1.0333e-02, -1.0450e-02, -1.4161e-02,\n",
      "         3.3437e-05,  6.8312e-04,  1.5441e-02], grad_fn=<UnbindBackward0>)\n",
      "the: tensor([ 7.7580e-03,  2.2613e-03, -1.9444e-02, -1.7131e-02, -1.3234e-02,\n",
      "         1.4102e-02, -3.7121e-03, -1.0888e-02,  6.2255e-03, -3.4778e-02,\n",
      "        -7.7945e-03, -1.4488e-02, -1.1725e-02,  1.0181e-02, -5.9442e-03,\n",
      "        -2.9660e-03,  2.9770e-02,  1.1039e-02, -2.3233e-03,  1.6797e-02,\n",
      "        -3.3526e-03, -7.7398e-03, -9.5659e-03,  3.5278e-02,  1.6044e-02,\n",
      "        -1.1838e-02, -6.1594e-02,  2.3611e-02,  1.8346e-02,  4.2340e-03,\n",
      "         5.7521e-03, -1.1895e-02, -1.1459e-02,  1.0338e-02, -7.4858e-03,\n",
      "        -1.2210e-02,  1.1579e-02, -4.4648e-03,  1.8507e-03,  3.2874e-02,\n",
      "         2.0269e-02, -1.0805e-02, -1.7823e-02, -1.0547e-02,  1.4330e-02,\n",
      "        -4.6706e-03,  1.2411e-02,  8.7913e-03,  2.5832e-02, -1.9322e-02,\n",
      "        -1.6042e-02,  1.8402e-02,  5.7965e-03,  6.9742e-03,  1.0627e-03,\n",
      "        -1.1839e-02,  3.2766e-03,  5.6590e-03,  1.2977e-02, -2.3732e-02,\n",
      "         6.6523e-03,  1.8803e-02, -5.2520e-02, -9.7932e-03, -4.4815e-04,\n",
      "        -7.2540e-03,  6.2635e-03, -6.7934e-03, -8.6924e-03,  1.9303e-02,\n",
      "        -1.2093e-03,  3.8141e-03,  8.1890e-03,  1.2594e-02,  2.6169e-02,\n",
      "        -2.8710e-02,  1.0907e-02,  5.9799e-02,  2.3220e-02, -8.8427e-03,\n",
      "        -6.4409e-03, -1.4377e-02, -1.3625e-02,  1.9394e-03,  2.2168e-03,\n",
      "         8.2807e-03,  5.5499e-03,  2.0903e-02,  1.0125e-02, -1.3484e-02,\n",
      "         1.3424e-02, -2.9831e-02,  1.7922e-03,  1.7009e-02, -2.7647e-03,\n",
      "        -5.1130e-03, -2.9003e-02, -1.1331e-02, -4.1950e-03, -1.0809e-02,\n",
      "         1.1575e-02, -1.0788e-02, -4.1933e-04,  6.1336e-03, -1.3832e-02,\n",
      "         1.1304e-01, -4.5835e-03,  4.3121e-03, -3.0880e-02,  1.8578e-02,\n",
      "         1.0282e-02,  2.7254e-02,  5.3195e-03,  1.6954e-03,  1.6752e-02,\n",
      "        -5.6954e-03, -1.0459e-02,  3.8589e-03,  6.7083e-03,  1.6007e-02,\n",
      "         1.3210e-02,  2.4584e-02,  1.4825e-02, -2.1442e-02,  4.2893e-02,\n",
      "        -1.9053e-03, -2.2573e-02,  2.3565e-02,  7.9627e-03, -1.3816e-02,\n",
      "        -1.2705e-02,  6.3779e-03, -3.7142e-02,  8.5963e-03, -8.1236e-03,\n",
      "         1.7525e-02, -1.9687e-03,  1.1513e-02, -7.2157e-03, -8.1920e-02,\n",
      "         3.7321e-03,  1.9699e-02,  2.6431e-02, -9.1513e-03,  2.0360e-03,\n",
      "        -5.9362e-02,  4.9618e-03,  2.3779e-02, -1.2194e-02, -1.0921e-03,\n",
      "         7.7799e-03, -4.2461e-05,  2.0312e-02, -1.6159e-02,  1.2074e-02,\n",
      "        -9.0501e-03, -1.3058e-02, -1.1633e-02,  1.0050e-02,  4.8486e-02,\n",
      "         1.9721e-02, -5.9694e-03,  6.5745e-03, -1.8368e-03, -1.5896e-03,\n",
      "         9.5749e-03, -4.6111e-05,  1.1033e-02, -1.0814e-01, -1.7989e-02,\n",
      "         8.6105e-03, -3.1395e-02,  8.9192e-05, -2.1868e-02,  4.4886e-03,\n",
      "         8.6131e-02,  1.9279e-02, -2.9976e-03, -1.6631e-02, -3.1110e-02,\n",
      "         3.2835e-03,  2.5717e-02, -9.2272e-04, -5.6165e-03, -9.1150e-03,\n",
      "         8.1094e-03, -1.2091e-02, -7.0910e-03, -4.8499e-03,  1.9435e-02,\n",
      "         1.2197e-02,  7.7294e-03,  1.1826e-02, -2.1713e-03,  1.1592e-02,\n",
      "        -5.4633e-03,  7.8073e-03, -1.4510e-02,  1.4307e-02, -3.5172e-02,\n",
      "        -2.0987e-02, -2.4089e-03, -2.3338e-03,  2.3331e-02,  2.0573e-03,\n",
      "         2.7978e-02, -2.2500e-02,  6.9266e-04,  3.1739e-03, -7.1396e-03,\n",
      "         7.3113e-03,  6.8957e-03,  1.4102e-02, -1.4270e-02, -1.8400e-02,\n",
      "         7.9529e-02,  1.1472e-02, -2.3795e-03,  5.3487e-02, -2.7211e-02,\n",
      "         9.7328e-03, -1.7600e-02, -6.0357e-03, -1.1246e-02, -1.1943e-02,\n",
      "        -3.4232e-02,  1.2735e-02,  5.2149e-02,  1.9333e-03, -1.6428e-03,\n",
      "        -1.7415e-02, -9.2705e-03,  4.9704e-03,  9.4521e-05, -5.6671e-03,\n",
      "        -1.4102e-02,  1.3214e-02, -5.5261e-03, -1.2470e-02, -1.4041e-02,\n",
      "        -6.3417e-03, -9.8457e-03,  1.6972e-02,  2.6062e-03, -3.9497e-02,\n",
      "         5.9171e-02,  2.2107e-02, -2.7851e-02, -7.9525e-03, -3.5030e-02,\n",
      "         8.9270e-03, -1.1889e-02,  2.5471e-02, -2.1623e-02,  5.6292e-03,\n",
      "        -9.6513e-04, -1.9585e-02,  2.0428e-02,  2.2227e-03, -2.0568e-02,\n",
      "        -2.2166e-02, -6.1919e-03,  2.1634e-03, -3.3297e-03, -2.8422e-02,\n",
      "         2.0717e-02,  9.9051e-04,  1.4507e-02, -9.6692e-03,  1.0342e-02,\n",
      "         4.1459e-04, -1.4210e-02,  7.5850e-03, -2.4026e-03, -6.4757e-03,\n",
      "        -2.2375e-02,  5.6306e-02, -1.3757e-02, -7.7493e-03, -3.9400e-03,\n",
      "         9.8899e-03, -6.5860e-03,  2.0365e-03,  3.6833e-03, -4.8753e-03,\n",
      "         2.4936e-02,  6.1541e-03, -1.2903e-02, -1.5674e-02, -4.6568e-03,\n",
      "         6.7799e-03,  8.5980e-02, -2.6863e-02, -3.0468e-03,  4.6086e-03,\n",
      "         1.2985e-02,  7.8572e-02, -5.0579e-03, -2.3960e-02,  3.1019e-03,\n",
      "         4.3769e-03, -1.0847e-02,  7.7608e-03, -2.2818e-02,  2.1526e-02,\n",
      "         2.4940e-03,  2.1761e-02, -1.7078e-03, -4.3754e-03, -3.0422e-03,\n",
      "        -2.2557e-02,  3.6788e-04,  6.7222e-03, -7.7262e-03,  6.5517e-03,\n",
      "        -4.0535e-03, -6.2181e-03, -1.6071e-02,  4.5388e-03,  2.2502e-02,\n",
      "         8.4689e-03,  4.7075e-03,  1.1283e-02, -4.5898e-03,  7.0481e-03,\n",
      "        -1.1163e-02, -3.5379e-03,  9.9308e-04,  1.4098e-02,  1.4824e-02,\n",
      "        -8.6936e-03,  3.4191e-02,  7.1701e-03,  7.6735e-03,  5.2789e-03,\n",
      "         1.3268e-02, -3.5309e-03,  3.0477e-03, -6.4020e-03, -7.0337e-03,\n",
      "        -1.0830e-02,  2.0322e-02,  5.7847e-03,  4.7758e-03, -1.3942e-02,\n",
      "        -1.0599e-01, -9.5087e-04,  4.4297e-03,  1.5905e-02, -5.5016e-03,\n",
      "         3.1849e-05, -6.6557e-03, -1.0126e-06,  1.1714e-01, -3.0296e-03,\n",
      "        -3.6374e-03, -2.9742e-03,  4.3404e-03,  8.3146e-03,  1.5778e-02,\n",
      "        -1.4748e-02, -8.5064e-03,  4.8257e-03, -1.1427e-02, -3.6241e-03,\n",
      "         9.9148e-03,  1.0226e-02, -1.3665e-02, -7.6966e-03,  1.6443e-02,\n",
      "         2.4905e-03, -1.6923e-03, -3.8707e-03, -2.1336e-02,  2.1382e-02,\n",
      "         1.1916e-02, -5.5558e-04, -1.7254e-02, -1.2533e-03, -1.0459e-02,\n",
      "        -1.2258e-02, -9.4626e-03, -5.9097e-03, -1.0970e-02, -4.2467e-03,\n",
      "         1.1102e-03, -2.4612e-03,  2.2320e-02,  2.0289e-02, -1.7398e-03,\n",
      "         3.0513e-02, -1.0569e-02, -5.6505e-03,  2.8478e-02, -2.6796e-03,\n",
      "        -2.5975e-02, -2.2340e-02,  1.3199e-02,  4.1009e-03,  6.6425e-03,\n",
      "         1.6326e-02,  1.7717e-03, -9.0202e-03,  1.6302e-02,  7.1587e-03,\n",
      "         1.3124e-02, -5.7650e-03,  2.3030e-02, -1.0805e-02,  6.5928e-03,\n",
      "         2.5056e-02,  5.6506e-03,  8.3704e-03, -1.8315e-02, -1.1906e-02,\n",
      "        -1.8068e-02,  1.5412e-02,  3.8527e-03, -2.2490e-02, -3.4083e-02,\n",
      "        -1.9241e-02, -2.6260e-03, -1.2556e-02,  3.1587e-02, -2.5777e-02,\n",
      "        -1.8056e-02, -9.6943e-03,  2.2915e-03,  1.4007e-02, -2.9240e-03,\n",
      "        -1.9163e-02,  6.8978e-03,  4.6073e-03,  7.1175e-03, -2.5971e-03,\n",
      "         2.5727e-03,  4.4735e-03,  7.6021e-03,  1.5428e-02,  1.3172e-02,\n",
      "        -1.0684e-02,  2.4358e-02, -3.3363e-03,  4.9652e-02,  2.6466e-03,\n",
      "        -3.1558e-02,  1.1951e-02,  5.7314e-03,  3.0217e-03, -1.5223e-03,\n",
      "         8.0002e-03,  6.9551e-03, -1.1959e-02,  7.9771e-03,  2.3962e-02,\n",
      "         1.1575e-03,  1.5580e-02, -2.7961e-02, -9.7875e-03,  1.2985e-02,\n",
      "         7.2814e-03,  8.0130e-02, -1.3471e-02, -8.6167e-03, -2.0848e-02,\n",
      "         1.3313e-02,  1.3742e-02, -3.6037e-04,  7.0273e-03,  4.5815e-03,\n",
      "        -1.1863e-02, -1.7383e-03, -1.5458e-03,  1.2976e-02, -6.1902e-03,\n",
      "        -1.0214e-02,  3.7518e-03, -1.8063e-02,  8.0768e-03,  1.3290e-02,\n",
      "         5.3890e-03,  3.8807e-03,  1.4245e-02, -1.2213e-02, -8.6374e-03,\n",
      "         1.6111e-03, -1.3396e-02,  1.0850e-02, -1.2736e-02,  2.1257e-02,\n",
      "         1.1434e-03, -1.4141e-02, -1.8034e-03,  1.8453e-02, -2.8514e-03,\n",
      "         7.7384e-03, -5.7324e-03, -2.4470e-02,  2.4201e-02,  2.6840e-03,\n",
      "        -8.0520e-03,  5.8653e-03,  1.2265e-02,  3.7635e-04, -8.7143e-03,\n",
      "         1.4993e-02, -2.6381e-03, -1.0863e-02, -2.8916e-03, -1.3734e-03,\n",
      "         1.7922e-02,  5.3531e-03, -1.0199e-03, -1.7955e-03,  4.6394e-03,\n",
      "        -3.9629e-03, -1.6025e-02,  7.0394e-02, -2.6037e-02, -2.7336e-02,\n",
      "        -2.4232e-02,  4.9679e-03, -7.6908e-03, -1.7940e-02, -1.4146e-02,\n",
      "        -1.1174e-02, -2.8486e-02,  1.8040e-02,  9.1737e-03, -1.0840e-01,\n",
      "         3.7604e-03, -9.3121e-03, -1.3299e-02,  1.2496e-02, -6.3689e-03,\n",
      "         9.6450e-03,  1.4108e-02, -1.7437e-03, -1.0951e-02, -6.3295e-03,\n",
      "        -2.4215e-02, -7.3034e-02,  2.5232e-02, -6.1589e-03,  9.6538e-03,\n",
      "         6.8414e-02,  2.7495e-02,  1.0351e-02,  1.7071e-02, -1.1883e-02,\n",
      "         1.2075e-02,  9.6379e-04,  3.0961e-03,  1.3525e-02, -1.0134e-03,\n",
      "         9.5542e-03, -2.0446e-02, -2.9470e-02,  1.5680e-02,  7.7662e-03,\n",
      "         2.4361e-02, -1.6550e-02, -1.5906e-02,  1.5208e-02,  4.7565e-03,\n",
      "         1.1545e-03,  2.0852e-04,  7.5160e-03, -3.2150e-02, -1.1460e-02,\n",
      "         6.0166e-03,  4.9008e-03, -1.0385e-02, -2.9920e-02,  1.5420e-02,\n",
      "         9.4974e-03, -1.3342e-02,  2.2915e-02, -1.5578e-02,  4.4045e-03,\n",
      "         1.7156e-02, -8.2138e-03,  8.1515e-03, -3.9976e-03,  2.0746e-02,\n",
      "         6.2943e-03, -2.7370e-03,  2.3265e-02,  5.3408e-03,  1.7429e-02,\n",
      "         1.0830e-03, -1.6254e-02, -1.8306e-03, -8.8831e-03, -7.4191e-04,\n",
      "         1.0836e-03,  1.0170e-02, -2.3080e-02, -1.1783e-03,  1.7859e-02,\n",
      "         4.7305e-03, -2.0959e-02,  1.0069e-02, -2.3709e-03,  1.1418e-02,\n",
      "        -7.0352e-03, -1.0463e-02, -1.4787e-02, -6.8607e-03, -2.8915e-03,\n",
      "         8.8401e-03,  1.3067e-03, -1.2627e-02, -3.2380e-02,  9.8535e-03,\n",
      "         1.4678e-02, -1.5013e-02, -1.1451e-02,  4.9911e-03,  6.5065e-03,\n",
      "        -6.9303e-03,  5.7658e-03,  3.0210e-02, -4.4838e-03, -6.0366e-03,\n",
      "         4.4410e-03,  7.2778e-03, -1.4356e-02, -2.6683e-02,  1.7218e-02,\n",
      "        -3.1014e-02,  3.8688e-03,  1.7669e-02, -5.8130e-03, -1.3648e-02,\n",
      "         6.6871e-03,  1.5775e-03, -1.0811e-02,  1.1289e-02, -1.1166e-02,\n",
      "         1.8016e-02, -1.9412e-02,  3.9365e-03,  1.3874e-02, -6.9486e-04,\n",
      "        -7.1792e-03, -1.0001e-03, -1.3136e-02, -5.0104e-03,  1.3054e-02,\n",
      "         1.2402e-02,  9.4839e-03, -4.7069e-03,  1.9830e-03, -9.6815e-02,\n",
      "        -1.1425e-02, -8.6818e-03, -9.2179e-03, -4.7188e-03,  2.4932e-03,\n",
      "         6.1781e-03, -3.3909e-03, -2.0276e-04,  1.6785e-02,  6.1878e-03,\n",
      "         7.5498e-03,  2.3788e-02, -1.4646e-02, -2.1115e-02,  2.7772e-03,\n",
      "         5.3409e-02, -1.5323e-02,  7.7880e-03, -8.7912e-03,  5.1772e-03,\n",
      "         9.6652e-03, -8.4539e-03, -1.4516e-02, -1.5516e-03, -1.5444e-02,\n",
      "        -2.3527e-02,  2.6505e-02,  4.4851e-03,  1.1661e-03,  1.3325e-02,\n",
      "         5.8740e-03,  2.1578e-02, -4.8053e-03,  1.4448e-02, -7.2053e-04,\n",
      "        -1.6883e-02, -2.7981e-02,  5.9633e-03, -1.1460e-03,  2.1279e-04,\n",
      "         1.4967e-02,  3.4529e-02,  4.7702e-03,  7.3128e-03, -5.5941e-02,\n",
      "         2.8597e-03, -9.2385e-03, -4.0823e-03,  3.9979e-03, -1.2851e-02,\n",
      "        -3.0966e-02, -5.2827e-02,  3.7916e-03,  2.1102e-02,  2.1728e-02,\n",
      "        -1.0166e-02, -4.6198e-03,  2.0670e-02, -5.5247e-03, -1.0236e-02,\n",
      "        -1.0390e-02, -1.8107e-02,  3.2936e-03,  3.6650e-03, -8.7420e-03,\n",
      "        -1.5254e-03, -9.7264e-04, -6.7598e-03,  3.3792e-03,  1.1938e-02,\n",
      "         8.4354e-03, -1.3898e-02,  1.2141e-02,  6.4312e-03,  1.3718e-03,\n",
      "         1.2299e-02, -8.0001e-03, -8.0780e-03, -8.6981e-03, -1.6408e-02,\n",
      "         2.5550e-02, -5.5686e-03,  2.7518e-03, -4.2028e-03,  3.0009e-02,\n",
      "        -6.5156e-03, -1.6249e-02, -1.5548e-02, -7.3927e-03,  6.0866e-03,\n",
      "         1.5624e-02,  2.3195e-03, -1.5710e-02,  2.1951e-02,  1.8442e-02,\n",
      "         5.4951e-04, -1.6665e-02, -1.3740e-02,  1.5054e-03,  4.9791e-03,\n",
      "        -6.9206e-03,  3.9549e-02,  1.9575e-02,  1.4175e-02,  1.7330e-02,\n",
      "        -1.1309e-02, -1.3354e-02,  1.0167e-02,  9.1845e-03,  4.9917e-03,\n",
      "         2.8910e-02,  2.9753e-02, -5.3247e-03], grad_fn=<UnbindBackward0>)\n",
      "cat: tensor([-1.1287e-02, -1.9644e-03, -1.1573e-02, -2.1680e-02, -1.0139e-02,\n",
      "         1.1552e-02,  5.5170e-03, -7.2400e-03, -2.5678e-03, -2.6875e-02,\n",
      "         2.4910e-02, -2.5304e-02,  1.4320e-02, -2.7072e-02, -2.7941e-03,\n",
      "         1.7596e-03,  5.3501e-03,  9.1149e-03, -7.3344e-03,  8.9849e-03,\n",
      "        -1.5942e-03, -2.5147e-02, -2.0495e-02,  8.4166e-03,  5.7252e-03,\n",
      "        -9.8943e-03, -2.9088e-02,  2.1893e-02,  7.1196e-03,  5.0403e-03,\n",
      "         1.2187e-02, -1.5493e-02, -1.5932e-02,  1.2149e-02, -2.9984e-03,\n",
      "        -6.9536e-03,  5.5220e-03, -5.2979e-03, -6.7038e-03, -1.6077e-03,\n",
      "         9.9436e-03, -6.6286e-03, -5.3495e-03,  1.4007e-04,  9.2702e-03,\n",
      "        -6.5428e-03,  5.6695e-03,  1.1161e-02,  2.4822e-02, -7.1355e-03,\n",
      "        -1.5949e-02,  1.6625e-02,  7.7116e-03,  8.9232e-02, -3.2846e-03,\n",
      "        -1.0085e-02, -1.0037e-02,  1.6346e-03,  1.0632e-02, -1.6124e-02,\n",
      "        -1.1065e-02,  5.0215e-03, -2.6401e-02,  2.0308e-03, -1.1635e-02,\n",
      "        -9.4326e-03,  4.4272e-03, -3.3250e-03,  5.4093e-03,  2.5073e-02,\n",
      "        -2.0713e-03,  1.3497e-03,  5.4772e-04, -7.0016e-03,  7.7704e-03,\n",
      "         1.1077e-02,  2.5871e-03,  7.6116e-03,  3.5555e-02, -2.0515e-02,\n",
      "        -4.5235e-03, -8.4425e-03, -7.8591e-03,  3.2944e-03, -9.3145e-03,\n",
      "        -1.8508e-02,  1.0141e-02,  1.5108e-02,  1.4844e-02, -4.1132e-03,\n",
      "         2.6700e-02, -1.9872e-02, -1.3617e-02,  1.3634e-02,  2.7748e-03,\n",
      "        -4.9959e-03, -4.7416e-02, -9.2777e-03, -1.4275e-02, -1.5448e-02,\n",
      "         4.5546e-03, -1.0905e-02,  8.0308e-03,  4.0896e-03, -8.0909e-03,\n",
      "         7.3265e-02, -9.0078e-03,  4.7706e-03, -2.2399e-02,  2.5961e-02,\n",
      "         7.5154e-03,  2.4240e-02, -3.8623e-03, -3.3654e-04,  1.4370e-02,\n",
      "        -7.0664e-04,  2.2074e-04, -9.3109e-03,  7.8770e-03, -3.2212e-04,\n",
      "         1.7937e-02, -1.3445e-02,  1.5323e-02, -2.5881e-02,  8.9190e-03,\n",
      "         8.8286e-03, -1.4970e-02,  9.8010e-03,  1.1728e-02,  1.0293e-02,\n",
      "        -4.1305e-03,  6.7095e-03, -1.1626e-02, -3.7056e-03,  4.9342e-03,\n",
      "         8.9704e-03, -6.8665e-03,  6.0222e-03, -1.2480e-02, -6.3984e-02,\n",
      "         5.6748e-03,  1.5731e-02,  5.5538e-03, -1.5917e-02, -2.4427e-03,\n",
      "        -5.0368e-02,  8.1647e-03,  2.9566e-02,  1.1134e-02,  1.8052e-02,\n",
      "         2.5785e-02, -5.6070e-04,  2.4360e-02, -2.9315e-03,  1.3053e-02,\n",
      "         4.0602e-03, -6.7522e-03,  2.0019e-03,  7.0702e-04,  5.8229e-02,\n",
      "         9.2902e-03, -5.0602e-03, -6.8825e-03,  1.3196e-03, -4.1099e-03,\n",
      "         1.2250e-02, -7.7749e-03,  8.8712e-03, -3.5621e-02, -3.0260e-02,\n",
      "         4.2389e-03, -3.5079e-02,  2.3625e-03, -2.0669e-02,  3.1606e-03,\n",
      "         7.0668e-02,  4.4051e-03,  2.9295e-03, -1.4632e-02, -1.9422e-02,\n",
      "         5.8745e-03,  6.1428e-03, -1.9091e-02, -9.3517e-03, -6.8053e-03,\n",
      "         3.3328e-03, -2.4007e-02,  2.2258e-03, -8.9534e-03,  1.4897e-02,\n",
      "         7.4245e-03,  6.6005e-03,  1.3491e-02, -3.1112e-03,  1.1886e-02,\n",
      "        -5.4733e-03,  6.5986e-03, -6.8988e-03,  4.1396e-04, -1.6124e-03,\n",
      "         5.8223e-03, -5.9932e-03,  8.2027e-02,  1.1238e-03, -6.3952e-03,\n",
      "         6.9668e-03, -1.2687e-02,  4.6550e-03, -3.7250e-03, -4.0009e-03,\n",
      "        -1.1574e-02, -1.1104e-02,  8.6989e-03, -4.8443e-03, -1.3590e-02,\n",
      "        -2.7843e-02,  7.8247e-03, -2.6030e-04, -4.5531e-02, -1.7277e-02,\n",
      "         3.7967e-03, -9.7180e-03, -1.0595e-02,  1.5640e-02, -1.8695e-02,\n",
      "        -3.6196e-02,  2.8103e-02,  1.5403e-02,  2.6772e-03, -8.2422e-03,\n",
      "         1.0386e-02, -1.1921e-02, -3.8416e-03, -3.1835e-03, -1.2905e-02,\n",
      "        -4.3192e-03,  4.8921e-03, -5.2276e-03, -5.5773e-03, -8.5705e-03,\n",
      "        -1.3853e-03, -6.1603e-03,  1.6111e-02,  4.8053e-03, -1.6492e-02,\n",
      "         7.5430e-02,  9.2317e-03, -1.0954e-02, -1.2172e-02,  4.0842e-02,\n",
      "         1.3550e-02, -9.5876e-03,  1.8465e-02, -6.4740e-03, -1.2316e-03,\n",
      "        -1.0277e-02, -1.7416e-02,  1.0322e-02, -1.4747e-02, -1.0996e-02,\n",
      "        -1.6964e-02, -1.2773e-02,  8.5768e-03, -2.3700e-03, -1.2689e-02,\n",
      "         2.6102e-02, -6.2545e-03,  3.6837e-03,  5.6055e-03,  4.2662e-03,\n",
      "         6.8027e-03,  6.0327e-03, -3.1381e-04, -7.4667e-03, -1.3841e-02,\n",
      "        -7.0634e-03,  3.1684e-02, -1.4183e-02,  6.4869e-04, -2.8188e-02,\n",
      "         1.4125e-02, -1.1119e-02, -3.6480e-03,  7.3271e-02, -2.2500e-03,\n",
      "         1.6833e-02,  1.0878e-02, -7.9814e-03, -8.5148e-03, -6.7117e-03,\n",
      "        -7.1994e-03,  3.7449e-02, -1.7127e-02, -1.7450e-02,  5.2454e-03,\n",
      "        -1.1928e-02, -6.7241e-02,  3.4415e-04, -2.2088e-02,  6.3171e-03,\n",
      "         4.2579e-03, -1.2435e-02,  5.3268e-03, -1.5197e-02,  1.9449e-02,\n",
      "        -1.3282e-02,  2.5561e-02, -1.3522e-02, -4.4343e-03, -9.0951e-04,\n",
      "         3.9863e-03,  8.3215e-02,  1.5026e-03, -2.8491e-03,  3.8803e-03,\n",
      "         1.2570e-02, -9.2276e-03, -1.4116e-02,  5.6104e-03,  4.4729e-02,\n",
      "         2.8006e-03,  4.0837e-04,  1.1700e-02,  6.9715e-03, -7.3852e-03,\n",
      "        -1.4332e-02, -7.3441e-03, -4.2040e-03,  5.5902e-03,  1.3109e-02,\n",
      "        -7.4267e-03,  7.4965e-02,  5.0611e-03,  1.3331e-02,  8.6400e-03,\n",
      "         1.5402e-03, -1.7701e-02, -9.1587e-04, -1.5397e-02, -2.3438e-03,\n",
      "         9.9345e-03,  4.0987e-03,  1.4194e-02,  7.3939e-03, -3.4668e-03,\n",
      "        -1.1766e-01, -7.4936e-03,  5.4813e-03,  1.5678e-02, -7.1368e-03,\n",
      "        -1.2109e-02, -9.9907e-03,  1.9775e-03, -3.5815e-02, -6.1995e-03,\n",
      "         1.6156e-03,  7.8281e-03,  9.7776e-03,  3.0169e-03, -8.5933e-03,\n",
      "        -5.4552e-03, -4.2422e-03, -9.6983e-03, -2.7489e-03,  7.2406e-03,\n",
      "         7.2402e-03,  6.7177e-03,  8.1820e-03,  4.8848e-03, -1.8195e-03,\n",
      "         1.2293e-02, -9.8130e-04,  7.1890e-04, -4.6662e-03,  9.4790e-03,\n",
      "         1.4425e-04, -7.6813e-03, -1.9742e-02,  1.4665e-02, -2.2919e-03,\n",
      "        -7.3007e-03, -1.6339e-03, -5.2944e-03, -4.5439e-03, -4.9378e-03,\n",
      "        -1.7135e-03,  4.9982e-03,  2.6692e-02,  1.8433e-02, -1.7660e-03,\n",
      "         2.7649e-03, -3.0171e-03,  3.7930e-03,  1.5258e-03, -5.8244e-03,\n",
      "        -1.9934e-02, -5.3259e-03, -4.9730e-03, -1.2172e-02,  1.1465e-02,\n",
      "         1.2194e-02, -1.1084e-02, -2.6981e-02,  7.6377e-03,  1.0031e-02,\n",
      "         9.0732e-03, -1.3041e-05,  1.0921e-02, -2.3146e-02, -3.4216e-03,\n",
      "         2.0600e-02,  1.9290e-02, -2.4757e-03, -1.9076e-02, -1.3013e-02,\n",
      "        -9.3288e-03,  2.3165e-02,  7.1600e-03, -1.5289e-02,  1.7866e-02,\n",
      "        -2.2768e-02, -1.6819e-02, -1.1331e-02,  2.0731e-02, -1.2591e-02,\n",
      "        -1.1974e-02, -1.6240e-04,  1.5684e-02,  9.1272e-03,  1.0856e-02,\n",
      "        -1.1923e-02,  2.7922e-02,  8.2301e-03,  5.2563e-03, -5.5021e-03,\n",
      "         3.8286e-03, -1.3035e-04,  4.0827e-02,  1.1668e-02,  1.9167e-02,\n",
      "        -1.9624e-03,  8.0469e-03, -6.4307e-03, -3.6316e-02,  3.5871e-03,\n",
      "        -1.1495e-02,  1.3267e-02,  9.8023e-04, -9.5526e-04,  1.1325e-02,\n",
      "         6.9136e-04,  1.7897e-03, -9.3913e-04,  9.3202e-03,  1.8097e-02,\n",
      "        -9.9596e-03,  1.0344e-03, -3.7161e-02, -8.6822e-03, -5.0234e-03,\n",
      "        -1.0709e-02,  1.0169e-01, -5.9416e-03, -5.5564e-03, -2.0016e-02,\n",
      "         1.9826e-02,  7.5013e-03, -1.5074e-02, -6.7446e-03,  7.8858e-03,\n",
      "        -6.9308e-04,  9.4511e-03,  1.0210e-03,  9.9872e-03, -7.4843e-03,\n",
      "         9.1960e-03, -5.2009e-03, -2.8621e-03, -9.2084e-03,  1.6890e-02,\n",
      "        -3.0571e-03,  2.2600e-02,  5.4918e-03, -2.1552e-03, -1.3801e-03,\n",
      "        -2.2838e-02, -1.1857e-02,  7.0777e-03, -3.9568e-03,  1.0725e-02,\n",
      "        -8.4839e-04, -1.2249e-02,  9.9860e-03,  2.4744e-02,  6.6222e-03,\n",
      "         6.5382e-03,  2.1099e-02, -2.3899e-02,  1.4883e-02,  9.0184e-03,\n",
      "        -2.0277e-03, -3.6375e-03, -9.3741e-03,  3.7570e-03, -2.4517e-02,\n",
      "        -7.6227e-04, -1.5205e-02, -2.0517e-02,  4.4909e-04, -1.2572e-02,\n",
      "         1.0598e-02, -8.4690e-03,  2.2280e-03,  1.4416e-02, -6.5543e-04,\n",
      "        -7.5499e-04, -1.9109e-02,  8.7719e-02, -1.3659e-02,  1.2133e-03,\n",
      "        -7.6291e-03, -1.2021e-02, -8.9793e-03, -1.2225e-02, -8.7153e-03,\n",
      "        -9.4201e-05, -1.4314e-02,  1.4201e-02,  4.1103e-03, -1.6159e-02,\n",
      "        -9.6593e-03,  3.5050e-03, -1.4360e-02,  7.0244e-03, -8.9970e-03,\n",
      "         1.5018e-02,  1.8318e-02, -6.1794e-03, -1.1094e-03, -5.5408e-03,\n",
      "        -2.0051e-02, -1.2321e-01,  1.8592e-02,  6.6902e-03,  1.8017e-02,\n",
      "        -1.8206e-03,  4.4594e-03,  1.3023e-02, -8.7488e-04, -1.5751e-02,\n",
      "         1.3575e-02,  8.2366e-03,  1.1158e-02,  8.8145e-03,  4.8103e-03,\n",
      "        -6.1224e-03, -1.8527e-02, -2.1519e-02,  1.6357e-02, -1.9007e-03,\n",
      "         6.3991e-03, -2.2848e-02, -1.8491e-03,  1.7792e-02, -3.5222e-03,\n",
      "         4.6261e-03,  1.0444e-02, -1.0827e-03, -2.3898e-02, -5.7046e-03,\n",
      "         5.8246e-03,  1.4033e-02, -9.3475e-03, -3.2386e-02,  5.4540e-03,\n",
      "        -1.3757e-03,  1.5035e-03, -1.0261e-01, -9.6480e-03,  4.1506e-03,\n",
      "         2.0712e-02, -1.6594e-03, -3.1082e-03, -8.5759e-03,  1.8193e-02,\n",
      "        -4.8330e-03, -5.8632e-04,  9.2413e-03, -5.9715e-03,  8.3912e-03,\n",
      "        -3.7860e-03,  8.5875e-03, -3.2423e-03,  7.8442e-04, -1.7767e-02,\n",
      "        -9.1694e-03,  1.0113e-02, -2.6719e-02,  1.2056e-02,  2.3869e-02,\n",
      "         1.6658e-02, -2.1087e-02,  9.0608e-03, -2.1029e-02,  2.5441e-02,\n",
      "        -1.1969e-03, -3.2499e-03,  1.6478e-02, -2.8747e-03, -6.2051e-03,\n",
      "         5.3267e-03, -1.9026e-03, -3.0228e-03, -2.4561e-02, -2.9820e-03,\n",
      "        -1.0706e-03, -8.7941e-03, -1.4792e-02, -8.7583e-05,  5.0596e-03,\n",
      "         8.9895e-03,  1.2960e-03,  2.1915e-02,  1.0113e-02,  1.0025e-03,\n",
      "        -1.1141e-03, -2.2987e-03, -1.0166e-02, -1.2223e-02,  4.0151e-03,\n",
      "        -1.3232e-03, -4.2326e-03,  9.3856e-04,  1.4974e-02,  5.1927e-03,\n",
      "        -1.3583e-03, -4.8026e-03,  1.1639e-03,  1.7332e-02,  6.7369e-03,\n",
      "         1.7281e-02, -2.1327e-02,  7.1218e-04,  1.6590e-03,  4.3952e-03,\n",
      "        -3.0723e-02, -6.9282e-03, -1.2489e-02,  1.2557e-02, -2.8494e-03,\n",
      "         1.5339e-03,  1.4135e-02, -1.2499e-02,  1.0787e-02, -3.4421e-02,\n",
      "         4.8293e-03,  2.5087e-02, -1.2939e-02, -8.0854e-03, -6.3347e-03,\n",
      "        -2.9152e-03,  1.8603e-03,  1.3701e-02,  1.1273e-02, -2.4136e-03,\n",
      "        -3.5183e-03,  1.9875e-02, -8.5146e-03, -1.1100e-02,  5.9229e-03,\n",
      "         2.6941e-02, -9.6601e-03,  1.2873e-02,  5.6024e-03,  1.3376e-03,\n",
      "        -7.6299e-05, -1.5644e-02,  1.0228e-03, -1.2519e-03, -1.7736e-02,\n",
      "        -2.0163e-02,  9.5045e-03,  7.2328e-03, -1.5587e-02,  4.8843e-03,\n",
      "         8.2678e-03,  2.1370e-02, -5.0465e-03,  2.8635e-03,  8.3275e-03,\n",
      "         6.8982e-03, -1.5001e-02,  1.2231e-02, -1.3523e-03,  9.9709e-03,\n",
      "         6.7683e-03,  1.5782e-02,  2.3957e-02,  4.6409e-03, -3.2735e-03,\n",
      "         8.0872e-03, -1.3661e-02,  5.1155e-03,  1.5144e-02, -1.0526e-02,\n",
      "        -2.8433e-02, -3.3730e-03, -7.4724e-04, -2.8130e-03,  1.3909e-02,\n",
      "        -1.2500e-02,  8.2088e-04,  2.4927e-02, -1.5978e-02,  2.6547e-03,\n",
      "        -6.7467e-03, -1.4246e-02,  2.7302e-03, -1.9562e-03, -1.5509e-03,\n",
      "         4.3048e-03, -1.5052e-02, -5.8462e-03,  4.0337e-03,  6.4854e-03,\n",
      "         4.6320e-03, -1.5756e-02,  7.0699e-03,  5.7368e-03,  3.1832e-03,\n",
      "         5.3131e-03, -8.8655e-03,  3.9601e-03, -5.4349e-03, -1.3383e-02,\n",
      "        -2.3702e-03, -1.2805e-02,  4.2170e-03, -4.7909e-03,  1.6880e-02,\n",
      "        -8.7450e-03, -7.6065e-03, -1.3453e-02, -9.9953e-03, -2.0710e-03,\n",
      "        -9.7273e-04,  5.7842e-03, -6.4992e-03,  1.6204e-02,  2.3556e-02,\n",
      "         1.5327e-03,  2.2933e-03,  9.0286e-03, -6.2112e-03,  2.9699e-03,\n",
      "         4.2026e-03,  2.7137e-02,  2.0121e-02,  1.7203e-02,  1.1804e-02,\n",
      "        -8.2494e-04, -3.3103e-03, -9.1549e-03,  7.6174e-03, -1.7656e-03,\n",
      "         1.4908e-02,  1.8741e-02, -7.3140e-03], grad_fn=<UnbindBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for _id, (token_id, pos_emb) in enumerate(zip(tokens_01['input_ids'][0], tokens_position_embeddings[0])):\n",
    "    token = tokenizer.decode([token_id])\n",
    "    print(f\"{token}: {pos_emb}\")\n",
    "    if _id==2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b815c53a-78e4-4229-a77d-4274466c0336",
   "metadata": {},
   "source": [
    "***\n",
    "# using model & corresponding component directly\n",
    "The model page of HuggingFace provides the code for how to use the model. \n",
    "Usually, there are two ways to use HuggingFace models\n",
    "- using model & corresponding component directly\n",
    "- using pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4485144e-e6f5-45d5-af30-1b18d2695aca",
   "metadata": {},
   "source": [
    "The web page of Hugging Face provides the code example of using the model or the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ccddad-c8f9-4544-94f3-5716fa85e2a6",
   "metadata": {},
   "source": [
    "The downloaded model would go to `~/.cache/huggingface/hub/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0d653c9-c0c8-4df6-b1d1-ceacffb2d431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models--bert-base-uncased  models--huaen--question_detection  version.txt\n"
     ]
    }
   ],
   "source": [
    "!ls ~/.cache/huggingface/hub/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10521f85-3dec-4eaf-828d-91388edecfdd",
   "metadata": {},
   "source": [
    "## Use Models directly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4624126-cecd-44f0-a343-e60897da70af",
   "metadata": {},
   "source": [
    "First step is prepare the `Tokenizer`. We would use `AutoTokenizer` to demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f4f0310-eeaf-46d1-8387-0612a72dd3cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b15ee4152d1946cda59a773f42cad592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18537ece1ab34158aa4272bde3fb0daa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4014fcb3ee824a20beaa6ffeaf4377ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec98d42-5409-401f-be7d-47da1a671c33",
   "metadata": {},
   "source": [
    "Next, we use `AutoModelForSequenceClassification` to perform classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02b8b902-af6b-43e2-8bcb-81a6190734ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b88318c92c24dd7ac4c500d58f3ed8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c94aa3f7-2971-45ac-ab77-945acf673cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models--bert-base-uncased\n",
      "models--distilbert--distilbert-base-uncased-finetuned-sst-2-english\n",
      "models--huaen--question_detection\n",
      "version.txt\n"
     ]
    }
   ],
   "source": [
    "!ls ~/.cache/huggingface/hub/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b8c3c5-3890-46f2-8547-0bb2ef5261e6",
   "metadata": {},
   "source": [
    "after loading tokenizer & model, we tokenize the input texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5410f2e-eb20-415b-97b2-402562ad8c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  1045,  3866,  1996,  3185,  1010,  2009,  2001, 10392,   999,\n",
      "           102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "text = \"I loved the movie, it was fantastic!\"\n",
    "\n",
    "tokens = tokenizer(text, return_tensors='pt')\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87372e64-7fbc-49b6-99c9-edadd8a926fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[-4.3428,  4.6955]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "outputs = model(**tokens)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdd46c1-86be-414f-92b3-e10909f45d11",
   "metadata": {},
   "source": [
    "we need to further distinguish if the text is +ve or -ve by the values under the key `logits` of output object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afd5f369-32a6-4c75-97a6-59b68f67871b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "predict_label = torch.argmax(outputs.logits)\n",
    "print(f\"Predicted sentiment: {'Positive'  if predict_label==1 else 'Negative'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13718663-eda0-40b5-85ef-cf9fbba918c2",
   "metadata": {},
   "source": [
    "## Use Pipelines\n",
    "Hugging Face provides the convenient, user-friendly `pipeline()` function that shields the lower-level details from developer. What you need to do is specifying task and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d8edc30-f4e2-4a8d-ac2f-d1e4523d60c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model = pipeline(task='text-classification', model='distilbert/distilbert-base-uncased-finetuned-sst-2-english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e89f3089-3eb5-4445-a813-074199844e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "review1 = '''From the warm welcome to the exquisite dishes and impeccable\n",
    " service, dining at Gourmet Haven is an unforgettable experience that\n",
    " leaves you eager to return.'''\n",
    " \n",
    "review2 = '''Despite high expectations, our experience at Savor Bistro \n",
    " fell short; the food was bland, service was slow, and the overall\n",
    " atmosphere lacked charm, leaving us disappointed and unlikely to\n",
    " revisit.'''\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "762a5f16-9c7a-4817-9a8c-4b252e9ef9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9998437166213989}, {'label': 'NEGATIVE', 'score': 0.9997773766517639}]\n"
     ]
    }
   ],
   "source": [
    "print(model([review1, review2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fccdc01-dc7e-494f-b628-8bff5e15b6c8",
   "metadata": {},
   "source": [
    "### Use cases of pipelines\n",
    "- Text Classifier\n",
    "- Text Generation\n",
    "- Text Summarization\n",
    "- Text Translation\n",
    "- Question Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dda45d4-7f4b-475b-b14d-e207cc779c9c",
   "metadata": {},
   "source": [
    "### Text Classifier\n",
    "Apart from the positive and negative reviews classification, Text Classifier task could also be applied to othe classification, e.g detecting question, detecting language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08cae07-d655-4e7e-b2c9-c01df950d35a",
   "metadata": {},
   "source": [
    "#### Question Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c41cd4d2-8e38-4912-8e75-8daacaca769b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    }
   ],
   "source": [
    "ques_detector = pipeline(task='text-classification', model=\"huaen/question_detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "590517c9-dcf0-4d38-9c13-d136e4380cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'question', 'score': 0.9975988268852234}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "response = ques_detector(\"Have you ever pondered the mysteries that lie beneath the surface of everyday life?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de0a5646-5379-418e-a837-3cd515efb4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'non_question', 'score': 0.9996671676635742}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "response = ques_detector('\"Life is a journey that must be traveled, no matter how bad the roads and accommodations.\" - Oliver Goldsmith\"')\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb58966-b78b-4b19-a4cc-38f70cab2b71",
   "metadata": {},
   "source": [
    "#### Language Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eef7ea4c-25b4-48c7-a379-a021827b0f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "lang_detector = pipeline(task='text-classification', model=\"papluca/xlm-roberta-base-language-detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c130161-206f-4d89-aa32-dc2ba70afc13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'ja', 'score': 0.9913387298583984}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = lang_detector(\"\")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf73f12-6ab0-44a6-9968-a0b61e79bf3d",
   "metadata": {},
   "source": [
    "#### SPAM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "382e3f33-f103-43fd-b9d9-ea0848311b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "spam_classifier = pipeline(task='text-classification', model=\"Delphia/twitter-spam-classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c94ef8f9-efc5-4da6-9ec4-26badc9e8dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 1, 'score': 0.744691789150238}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Congratulations! You've been selected as the winner of our \n",
    "exclusive prize draw. Claim your reward now by clicking on \n",
    "the link below!\n",
    "\"\"\"\n",
    "\n",
    "response = spam_classifier(text)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f0a50cd-5b54-4902-9f43-5e904ec1a7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 0, 'score': 0.7776529788970947}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Hi Jimmy, I hope you're doing well. I just wanted to remind \n",
    "you about our meeting tomorrow at 10 AM in conference room A. \n",
    "Please let me know if you have any questions or need any \n",
    "further information. Looking forward to seeing you there!\n",
    "\"\"\"\n",
    "\n",
    "response = spam_classifier(text)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096de14d-7172-4dab-bbe8-8952feb95e61",
   "metadata": {},
   "source": [
    "### Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "968f1590-c658-497e-9835-d11b60a613ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline(task='text-generation', model='openai-community/gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9dcffb42-112e-4b3e-9ae9-3897470f2b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "begin = \"In this course, we will teach you how to\"\n",
    "\n",
    "responses = generator(begin, max_length=50, num_return_sequences=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec160f7f-fa28-4b5e-9c6b-7d9ff0053150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "178b1433-9592-4c44-994f-9c3bae5740d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generated_text': 'In this course, we will teach you how to create custom HTML5 video embeddable HTML5 files. It will be useful in order to understand basic HTML, HTML6, CSS, and Media Composer coding concepts and how to develop a complex'}\n"
     ]
    }
   ],
   "source": [
    "print(responses[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb4ab6b5-7659-45ae-9cb5-b15886e55264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generated_text': \"In this course, we will teach you how to write a complete set of rules and code, using some examples and examples from real life. In practice, you should look at a set of basic concepts that you'll be able to write about in this\"}\n"
     ]
    }
   ],
   "source": [
    "print(responses[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7920adf2-c83a-46bf-875c-e3249c1cd7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generated_text': 'In this course, we will teach you how to make a powerful web site with one simple technique.\\n\\nWe will also learn how to create an index, and a simple dashboard.\\n\\nOur goal is to help you quickly get your ideas.'}\n"
     ]
    }
   ],
   "source": [
    "print(responses[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd5a8ee-36c8-44fa-9031-46417e356a81",
   "metadata": {},
   "source": [
    "### Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3638125-8a60-4dda-9168-6fe91ff2e2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text_summarisation_usage.txt', 'r', encoding='utf-8') as f:\n",
    "    content = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd7baa07-b3b5-4490-8620-1168b0d87753",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(task='summarization', model='facebook/bart-large-cnn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48001f25-ac1e-4850-a8e7-a9a0a7d1364b",
   "metadata": {},
   "source": [
    "**Extractive Summarization**: involves selecting and extracting important sentences or phrases directly from the original text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4efd459-15a1-40bf-9b25-8ff1c92043fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'A quantum computer is a computer that exploits quantum mechanical phenomena. Classical physics cannot explain the operation of these quantum devices. A large-scale quantum computer could break widely used encryption. The current state of the art is still largely experimental and impractical. The basic unit of information in quantum computing is the qubit, similar to the bit in traditional digital electronics. The design of quantum algorithms involves creating procedures that allow a quantum computer to perform calculations efficiently. The study of the computational complexity of problems with respect to quantum computers is known asquantum complexity theory.'}]\n"
     ]
    }
   ],
   "source": [
    "response = summarizer(content, min_length=100, max_length=250, do_sample=False)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051d8923-8a15-49d9-8d83-575bca6569b6",
   "metadata": {},
   "source": [
    "**Abstractive Summarization**: generates summaries by paraphrasing and rephrasing the original text in a more concise form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34bcb712-5814-4655-8c4a-d5d7b7fcf65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'A quantum computer is a computer that exploits quantum mechanical phenomena. Classical physics cannot explain the operation of these quantum devices. A large-scale quantum computer could break widely used encryption. The basic unit of information in quantum computing is the qubit, similar to the bit in traditional digital electronics. The design of quantum algorithms involves creating procedures that allow a quantum computer to perform calculations efficiently. Any computational problem that can be solved by a classical computer can also be solved  by a quantum computers, at least in principle.'}]\n"
     ]
    }
   ],
   "source": [
    "response = summarizer(content, min_length=100, max_length=250, do_sample=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f03a22-659e-4b98-b653-50a164b29779",
   "metadata": {},
   "source": [
    "### Text Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd2e626f-2dc4-4bc3-95fc-a2f33c7de1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "translator = pipeline(task=\"translation_en_to_fr\", model=\"google-t5/t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "97c0d1f0-927a-4657-8ab5-fd4f4d876345",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_text=\"Wikipedia is hosted by the Wikimedia Foundation, a non-profit organization that also hosts a range of other projects.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "08ac2c82-2deb-4251-a3ae-cab8e3751df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': \"Wikipedia est hberge par la Wikimedia Foundation, un organisme sans but lucratif qui hberge galement une srie d'autres projets.\"}]\n"
     ]
    }
   ],
   "source": [
    "response = translator(en_text)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47344dcf-7800-4450-bf0b-c22080ddf47c",
   "metadata": {},
   "source": [
    "### Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d75d252-7cb5-42b6-9bdd-70997a767350",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "qa_model = pipeline(task='question-answering', model='deepset/roberta-base-squad2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "24838ecf-e93b-4ab0-a385-103ee753d18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('question_answering.txt', 'r', encoding='utf-8') as f:\n",
    "    context = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4657321b-ea9c-4b57-866a-0146b6c64c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/transformers/pipelines/question_answering.py:391: FutureWarning: Passing a list of SQuAD examples to the pipeline is deprecated and will be removed in v5. Inputs should be passed using the `question` and `context` keyword arguments instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.13809449970722198, 'start': 185, 'end': 194, 'answer': 'lion city'}\n"
     ]
    }
   ],
   "source": [
    "question = {\n",
    "    'question': 'What is the meaning of Singapura?',\n",
    "    'context': context\n",
    "}\n",
    "\n",
    "response = qa_model(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4722f4d5-aeeb-4e59-8797-b94196eb4083",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
