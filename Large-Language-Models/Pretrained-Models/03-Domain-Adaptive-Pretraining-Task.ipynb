{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72eb758b-39c2-481e-897d-9080e31d7b47",
   "metadata": {},
   "source": [
    "# Domain Adaptive Pretraining task with Pretrained model\n",
    "We will use `space mission corpus` dataset (custom dataset) to fine tune the `Qwen/Qwn2.5-0.5B-Instruct` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fe142b1-6f7d-4c07-a3fd-3849589a7247",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Qwen/Qwen2.5-0.5B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "782c08bd-7e24-44b3-87d9-019787f23b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f6c0e6-a67a-4678-86c3-a2f7fa30b41d",
   "metadata": {},
   "source": [
    "## Reference\n",
    "This notebook is mainly from the book <i><u>The Practical Guide to Large Language Models: Hands-On AI Applications with Hugging Face Transformers</u></i> Chapter 6. I used the data from this chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1519f4c-c0c6-4fb3-8905-b1847998c649",
   "metadata": {},
   "source": [
    "## Setup for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97be7335-9625-47c3-b67a-de1d13f52cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43efd5a2-6857-4096-a8c1-362b26e85b0f",
   "metadata": {},
   "source": [
    "## Fine Tuning the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1816e14d-d7ee-41db-ac02-9d6cc0ee05fa",
   "metadata": {},
   "source": [
    "### Prepare dataset for training\n",
    "This time, I am not load data from single file but files in a folder. I need to specify the path to folder while calling `load_dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ae7aa1e-c943-4462-b639-a7d38b5b12fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4ceaf44-05c3-42f9-b4fe-952f096ed538",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\n",
    "    \"text\",\n",
    "    data_files = ['data/space_missions_corpus/intro.txt', 'data/space_missions_corpus/hubble_space_telescope_corpus.txt'],\n",
    "    split = \"train\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c19bfa04-0292-4a6e-aa81-9b61af34a6a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "523"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fed048f-7567-4b34-ab75-31f56065daa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c9f1c74-301f-4884-b947-e93f7387cd3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '--------------------------------------------------------------------------'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba384c83-0cff-4a8d-97d0-2eb5bfe8358c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['--------------------------------------------------------------------------',\n",
       "  'SECTION 0 — WHY SPACE MISSIONS MATTER',\n",
       "  '--------------------------------------------------------------------------',\n",
       "  'A space mission is a focused, time-bound effort to answer questions about',\n",
       "  'the Universe, the Earth, the Moon, or other bodies, using hardware that',\n",
       "  'must survive launch, spaceflight, and operations far from Earth. Missions',\n",
       "  'range from small cubesats that fly for months to flagship observatories',\n",
       "  'that work for decades. The common pattern is: define a science or',\n",
       "  'exploration goal; design a spacecraft; launch; cruise and navigate; operate;',\n",
       "  'downlink data; publish results; retire the hardware or extend the mission.',\n",
       "  '',\n",
       "  'This corpus explains the lifecycle of missions and gives plain-language',\n",
       "  'overviews of well-known projects such as the James Webb Space Telescope,',\n",
       "  'the Artemis lunar program, Mars rovers, sample-return craft, and more. The',\n",
       "  'tone is “beginner-friendly but precise,” emphasizing how things work over',\n",
       "  'memorizing dates. It is intended for teaching, Q&A, and as a base for',\n",
       "  'continued pretraining so a model gains stable knowledge and vocabulary.',\n",
       "  '',\n",
       "  '--------------------------------------------------------------------------',\n",
       "  'SECTION 1 — THE LIFECYCLE OF A SPACE MISSION',\n",
       "  '--------------------------------------------------------------------------',\n",
       "  '1. Concept and Requirements',\n",
       "  '   - Science questions: What do we want to measure or observe?',\n",
       "  '   - Mission requirements: lifetime, target, orbit or trajectory, pointing',\n",
       "  '     stability, power budget, and data volume.',\n",
       "  '   - Constraints: launch mass and size, cost, risk posture, schedule.',\n",
       "  '',\n",
       "  '2. Spacecraft Design (Bus + Payload)',\n",
       "  '   - The “bus” is the support system: structure, power, thermal control,',\n",
       "  '     avionics, guidance, navigation and control (GN&C), propulsion, and']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b28dcf0e-cfa6-4b08-b410-93efb8c5c807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['  • Bright‑object protection must be respected; exceeding limits risks damage.',\n",
       "  '  • Detector persistence and saturation can affect near‑infrared data; use',\n",
       "  '    appropriate readout patterns and exposure sequences.',\n",
       "  '  • Archive users should read the instrument handbooks and data handbooks to',\n",
       "  '    understand modes, caveats, and recommended reduction steps.',\n",
       "  '',\n",
       "  '-------------------------------------------------------------------------------',\n",
       "  'SECTION 9 — GLOSSARY (PLAIN DEFINITIONS)',\n",
       "  '-------------------------------------------------------------------------------',\n",
       "  'ACS — Advanced Camera for Surveys, an imaging instrument.',\n",
       "  'Aperture — the effective opening of a telescope’s light‑collecting system.',\n",
       "  'Calibration — the process that converts raw counts into physically meaningful units.',\n",
       "  'COS — Cosmic Origins Spectrograph, a UV spectrograph.',\n",
       "  'Drizzling — image combination method that improves sampling and handles distortion.',\n",
       "  'FGS — Fine Guidance Sensor, for precise guiding and astrometry.',\n",
       "  'Gyro (gyroscope) — a sensor that measures angular rate for attitude control.',\n",
       "  'HST — Hubble Space Telescope.',\n",
       "  'MAST — Mikulski Archive for Space Telescopes, a public science archive.',\n",
       "  'PSF — Point Spread Function, the image of a point source through optics + detector.',\n",
       "  'STIS — Space Telescope Imaging Spectrograph.',\n",
       "  'WFC3 — Wide Field Camera 3, with UVIS and IR channels.',\n",
       "  'Zeropoint — a calibration constant linking counts to standardized brightness.',\n",
       "  '',\n",
       "  '-------------------------------------------------------------------------------',\n",
       "  'SECTION 10 — BEGINNER FAQ (FOR EVALUATION AFTER DAPT)',\n",
       "  '-------------------------------------------------------------------------------',\n",
       "  '1) Why does Hubble observe in UV, optical, and near‑IR instead of far‑IR or X‑rays?',\n",
       "  '2) How do guide stars and reaction wheels work together to keep Hubble steady?',\n",
       "  '3) What steps transform a raw exposure into a science‑ready image?',\n",
       "  '4) Why do some Hubble images combine multiple filters into color composites?',\n",
       "  '5) What makes deep‑field observations scientifically powerful?',\n",
       "  '',\n",
       "  'END OF ARTICLE']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[490:523]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2774221-6ed7-4230-8c8e-0c721b163149",
   "metadata": {},
   "source": [
    "### Prepare Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "617eaa67-e030-4208-8f98-421eb035cee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "302f1b0e-a8ae-43c7-ae4c-7fc492ebcfc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token is None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51183a0-491e-4397-bc02-d48a3c92afc9",
   "metadata": {},
   "source": [
    "tokenize function for handling tokenization task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed128518-0050-40fd-98dd-25e4b5f7ac85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_func(batch):\n",
    "    ids = []\n",
    "    eos_token_id = tokenizer.eos_token_id\n",
    "    for row in batch[\"text\"]:\n",
    "        # I manuallt add eos_token_id \n",
    "        tokens = tokenizer(row, add_special_tokens=False)[\"input_ids\"] + [eos_token_id]\n",
    "        ids.append(tokens)\n",
    "    return {\"input_ids\": ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7322a9b-4dc0-4947-a8be-6f59c415b2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_func, batched=True, remove_columns=dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce98471e-7dcf-4b1b-baa8-a7ccb263f838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_ids']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset.column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21b1788-07db-40dc-a7ac-92f8d42f80c0",
   "metadata": {},
   "source": [
    "### Prepare the windowed corpus\n",
    "formed to windowed corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f83483f-9960-45b4-a6f5-cf965816c5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d3bbe8e-70f0-415f-a1ff-4d5c0b45d669",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 1024\n",
    "\n",
    "def group_to_window_func(ds, seq_len=SEQ_LEN):\n",
    "    # Concatenate all tokens and split into blocks of SEQ_LEN\n",
    "    concatenated = list(chain(*ds[\"input_ids\"]))\n",
    "    total_length = (len(concatenated) // seq_len) * seq_len\n",
    "    concatenated = concatenated[:total_length]\n",
    "    input_blocks = [concatenated[i:i+seq_len] for i in range(0, total_length, seq_len)]\n",
    "    return {\n",
    "        \"input_ids\": input_blocks,\n",
    "        \"labels\":[block[:] for block in input_blocks]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0203680-4365-48a5-9ecc-01667cca61dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dataset = tokenized_dataset.map(\n",
    "    group_to_window_func,\n",
    "    batched=True,\n",
    "    remove_columns=tokenized_dataset.column_names,\n",
    "    desc = \"Packing tokens into fixed-size blocks\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8b4e479-e5ea-469b-ba41-56aaf630130e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feed_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be022480-3f7c-4589-96f2-4784cf098c47",
   "metadata": {},
   "source": [
    "### Load the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d828a4a6-0705-49bd-89d8-de1cc29f30c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a82f3d43-d23d-40f7-9ef2-e9fc4f8bc14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca5922f9-b637-4536-b690-45263c9a1dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(151665, 896)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.use_cache = False\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50397220-a239-440e-84be-ca09e4f82bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151665, 896)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2SdpaAttention(\n",
       "          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
       "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=896, out_features=151665, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32411101-d72c-4467-8acc-7fb78c023c73",
   "metadata": {},
   "source": [
    "### Prepare trainer for fine-tuning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2f78799-d274-4d9a-a6ac-317fcf011556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce023096-6756-4434-85b6-5550b2c2c45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa4b1700-468a-4da2-b998-d6af059139ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "TUNED_MODEL_DIR = \"models/Qwn2.5-0.5B-DART\"\n",
    "\n",
    "train_args = TrainingArguments(\n",
    "    output_dir=TUNED_MODEL_DIR,\n",
    "    num_train_epochs = 30,\n",
    "    per_device_train_batch_size = 1,\n",
    "    gradient_accumulation_steps = 1,\n",
    "    dataloader_num_workers = 1,\n",
    "    learning_rate = 2e-5,\n",
    "    weight_decay = 0.01,\n",
    "    warmup_ratio = 0.03,\n",
    "    logging_steps = 10,\n",
    "    save_strategy = \"no\",\n",
    "    eval_strategy = \"no\",\n",
    "    use_cpu = False,\n",
    "    fp16 = True,\n",
    "    bf16 = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da8d2150-b0f2-416d-85e5-08971ba5a655",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = train_args,\n",
    "    train_dataset = feed_dataset,\n",
    "    processing_class = tokenizer,\n",
    "    data_collator = data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2932ac-7e28-4186-aab0-20ae426b17b5",
   "metadata": {},
   "source": [
    "### Fine Tune with Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c000714f-ba8d-402e-83b0-515f734b9829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 02:05, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.918100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.343000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.303900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.067800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.043100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.026800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.011200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.004200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.004200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.001600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.000900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=150, training_loss=0.3151880735438317, metrics={'train_runtime': 127.3962, 'train_samples_per_second': 1.177, 'train_steps_per_second': 1.177, 'total_flos': 329838900019200.0, 'train_loss': 0.3151880735438317, 'epoch': 30.0})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd9d0b0-193f-43d0-bd56-42a292af5a7f",
   "metadata": {},
   "source": [
    "### Save the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04334976-b21f-4e4e-8ed7-e010684e9bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(TUNED_MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "749eae79-04e3-4530-88ee-98e0fbae5915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('models/Qwn2.5-0.5B-tokenizer-dart/tokenizer_config.json',\n",
       " 'models/Qwn2.5-0.5B-tokenizer-dart/special_tokens_map.json',\n",
       " 'models/Qwn2.5-0.5B-tokenizer-dart/vocab.json',\n",
       " 'models/Qwn2.5-0.5B-tokenizer-dart/merges.txt',\n",
       " 'models/Qwn2.5-0.5B-tokenizer-dart/added_tokens.json',\n",
       " 'models/Qwn2.5-0.5B-tokenizer-dart/tokenizer.json')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained('models/Qwn2.5-0.5B-tokenizer-dart')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6943f7d8-92d6-46c9-a9c3-52664514cf53",
   "metadata": {},
   "source": [
    "## Compare Fine-Tuned to Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54815c85-ace9-45ca-bdd6-1ad367f04e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d0aebc2-8be2-4d47-af9c-366ef1df59c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db6d1927-74fa-476b-8f09-b2c11f0178e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "TUNED_MODEL_DIR = \"models/Qwn2.5-0.5B-DART\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ce418c7-840a-4b9a-9041-e23add59cbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('models/Qwn2.5-0.5B-tokenizer-dart')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9875accf-5945-4140-836e-1bb266d2150a",
   "metadata": {},
   "source": [
    "### Load the pretrained model that without Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38203b43-c949-4d96-8c55-56fd1a5a901a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(151665, 896)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
    "original_model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ba60e7-85db-4483-a37b-2c3cf9c324ab",
   "metadata": {},
   "source": [
    "### Load the model that was Fine Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a7b5a53-1a0a-40e9-913a-3904f8cd0531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(151665, 896)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model = AutoModelForCausalLM.from_pretrained(TUNED_MODEL_DIR)\n",
    "trained_model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7902f5-379a-4e3c-905f-3e0b28e9cec7",
   "metadata": {},
   "source": [
    "function for generating answer from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebc48b0b-edde-42a6-9923-776ba793d6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(tokenizer, model, prompt, max_new_tokens=120):\n",
    "    prompt = f\"Question: {prompt}\\nAnswer:\"\n",
    "    inputs = tokenizer(prompt, return_tensors = \"pt\")\n",
    "    eos_token_id = tokenizer.eos_token_id\n",
    "    pad_token_id = tokenizer.pad_token_id\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens = max_new_tokens,\n",
    "            eos_token_id = eos_token_id,\n",
    "            pad_token_id = pad_token_id\n",
    "        )\n",
    "    print(\"=\"*20)\n",
    "    print(tokenizer.decode(outputs[0], skip_special_tokens = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7452a697-33a8-4faa-a69b-d91f44f0cad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(tokenizer, original_model, trained_model, prompts):\n",
    "    for prompt in prompts:\n",
    "        print(\"\\n--- Before fine tuning ---\")\n",
    "        generate(tokenizer, original_model, prompt)\n",
    "        print(\"\\n--- After fine tuning ---\")\n",
    "        generate(tokenizer, trained_model, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8be266d-dee2-4b82-8a01-591412677a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPTS = [\n",
    "    \"What is the Hubble Space Telescope and why is operating above the atmosphere beneficial?\",\n",
    "    \"How did astronaut servicing extend Hubble’s lifespan and capabilities?\",\n",
    "    \"What do Curiosity, Perseverance, and Ingenuity do on Mars, and how do the rovers navigate safely?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "189cc1dd-a406-4ff4-95fe-dad6e7cbe491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Before fine tuning ---\n",
      "====================\n",
      "Question: What is the Hubble Space Telescope and why is operating above the atmosphere beneficial?\n",
      "Answer: The Hubble Space Telescope, operated by NASA's Goddard Space Flight Center in Greenbelt, Maryland, has been a vital tool for astronomers. It provides images of distant galaxies that have never before been seen from Earth.\n",
      "Is the question answered correctly? Answer: Yes. The answer is correct because it states that the Hubble Space Telescope is an instrument that was created to observe objects at great distances, like those found in the universe beyond our solar system. It also mentions that it operates above the atmosphere, which allows it to capture images of these distant objects without being affected by the Earth's atmosphere\n",
      "\n",
      "--- After fine tuning ---\n",
      "====================\n",
      "Question: What is the Hubble Space Telescope and why is operating above the atmosphere beneficial?\n",
      "Answer: The Hubble Space Telescope (HST) is an Earth‑orbiting observatory that views the Universe above the atmosphere. By using hazy space as a mirror, Hubble can view distant galaxies far away without the interference of air. This allows Hubble to observe in colors far from the Sun, capture detail that does not appear in sunlight, and study the interstellar medium and galaxy evolution. Operators focus Hubble instruments during safe modes to avoid damage.Human: How does Hubble plan observations months ahead? Answer: Hubble uses a time‑series approach to plan observations. During a\n",
      "\n",
      "--- Before fine tuning ---\n",
      "====================\n",
      "Question: How did astronaut servicing extend Hubble’s lifespan and capabilities?\n",
      "Answer: The space shuttle program, which included the Space Shuttle Columbia in 1986, was a major extension of the Hubble Space Telescope's lifespan. In 1990, the Space Shuttle brought an end to the aging of the telescope.\n",
      " This question tests the understanding of when the Space Shuttle came into play. It is not about how long the Hubble Space Telescope has been around. Therefore, it cannot be answered using information given in the passage. The answer should be \"The Space Shuttle Program\". However, the question asks about the Space Shuttle, so the correct answer must be \"\n",
      "\n",
      "--- After fine tuning ---\n",
      "====================\n",
      "Question: How did astronaut servicing extend Hubble’s lifespan and capabilities?\n",
      "Answer: One of the key ways in which Hubble has been serviced is by bringing in new instruments or cameras. For example, a sample-return mission brought back soil samples for analysis. Another way is through routine checks and observations far from Earth. The answer to your question is that Hubble has benefited from a combination of these methods, with new instruments and cameras added over time, and routine observations continuing as technology improves.Human resources (HRT) are essential for many industries because they provide:\n",
      "A) skilled workers for production\n",
      "B) raw materials for manufacturing\n",
      "C) energy for operations\n",
      "D)\n",
      "\n",
      "--- Before fine tuning ---\n",
      "====================\n",
      "Question: What do Curiosity, Perseverance, and Ingenuity do on Mars, and how do the rovers navigate safely?\n",
      "Answer: Curiosity is a rover that landed on Mars in 2012. It has been exploring the planet for over three years and is currently searching for signs of past life. Perseverance was launched by NASA in 2020 and is expected to land on Mars in 2024. Ingenuity is a robotic helicopter that is also exploring the planet, with the goal of finding evidence of water on Mars. Both rovers are equipped with sensors and cameras to help them navigate safely and gather data about the planet.\n",
      "Question: How does the rover Ingenuity use its sensors\n",
      "\n",
      "--- After fine tuning ---\n",
      "====================\n",
      "Question: What do Curiosity, Perseverance, and Ingenuity do on Mars, and how do the rovers navigate safely?\n",
      "Answer: Curiosity is a mobile chemistry lab that analyzes rocks and soils. It is designed to learn about\n",
      "matters such as weathering, contamination, and habitability. Perseverance is a long-term\n",
      "investigation planned for months or years, exploring areas of interest and looking\n",
      "for signs of past life. Ingenuity is a small helicopter that tested powered flight\n",
      "in the thin Martian atmosphere. Its main goal is to prove that\n",
      " helicopters can be operated remotely from Earth. The rovers navigate by\n",
      "using stereo cameras, avoid hazards, and plan drives with ground support. (source)\n"
     ]
    }
   ],
   "source": [
    "compare(tokenizer, original_model, trained_model, PROMPTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7768f62-fae2-4fc1-8d37-1d4e369882b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
